[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This is a companion for the book Generative AI Handbook by William Brown (copyright June 5, 2024).\nEach chapter title to the left is a link to a slide deck.\n\nThese slides are being developed by this club.\nEach deck will open in its own tab.\nYou may want to type “s” at the start of each deck to open the speaker notes.\nJoin the Data Science Learning Community to participate in the discussion!\n\nWe follow the Data Science Learning Community Code of Conduct.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#sources",
    "href": "slides/19_instruct-fine-tuning.html#sources",
    "title": "19. Instruct Fine-Tuning",
    "section": "Sources",
    "text": "Sources\nFollowing the Gen AI Handbook, we looked at\n\nblog post by Sebastian Ruder (Meta)\nvideo by Shayne Longpre (Google)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#module",
    "href": "slides/19_instruct-fine-tuning.html#module",
    "title": "19. Instruct Fine-Tuning",
    "section": "Module",
    "text": "Module\n\nfine tuning\n“… to add a small set of parameters to a pretrained LLM. Only the newly added parameters are finetuned while all the parameters of the pretrained LLM remain frozen.” — Sebastian Raschka (author, article)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#where-were-we",
    "href": "slides/19_instruct-fine-tuning.html#where-were-we",
    "title": "19. Instruct Fine-Tuning",
    "section": "Where were we?",
    "text": "Where were we?\n\nWei, et al., 2022",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#definition-seeking",
    "href": "slides/19_instruct-fine-tuning.html#definition-seeking",
    "title": "19. Instruct Fine-Tuning",
    "section": "Definition Seeking",
    "text": "Definition Seeking\n\ngetting definitions",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#instruction-guidance",
    "href": "slides/19_instruct-fine-tuning.html#instruction-guidance",
    "title": "19. Instruct Fine-Tuning",
    "section": "Instruction Guidance",
    "text": "Instruction Guidance\n\nproviding instructions",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#alignment-tuning-instruction-tuning",
    "href": "slides/19_instruct-fine-tuning.html#alignment-tuning-instruction-tuning",
    "title": "19. Instruct Fine-Tuning",
    "section": "Alignment Tuning = Instruction Tuning",
    "text": "Alignment Tuning = Instruction Tuning\n\nopen-ended tasks\ncreative generation\nhuman feedback",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#instruction-data",
    "href": "slides/19_instruct-fine-tuning.html#instruction-data",
    "title": "19. Instruct Fine-Tuning",
    "section": "Instruction Data",
    "text": "Instruction Data\n\nMixing few-shot settings\nTask diversity\nData Augmentation\n\ne.g. turning a question-answering task into a question-generation task\n\nMixing weights",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#natural-instructions-q",
    "href": "slides/19_instruct-fine-tuning.html#natural-instructions-q",
    "title": "19. Instruct Fine-Tuning",
    "section": "Natural Instructions: Q",
    "text": "Natural Instructions: Q\n\nquestion generation, Mishra et al., 2022\n193k instruction-output examples sourced from 61 existing English NLP tasks. Crowd-sourcing instructions from each dataset are aligned to a common schema. Instructions are thus more structured compared to other datasets.",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#natural-instructions-a",
    "href": "slides/19_instruct-fine-tuning.html#natural-instructions-a",
    "title": "19. Instruct Fine-Tuning",
    "section": "Natural Instructions: A",
    "text": "Natural Instructions: A\n\nanswer generation, Mishra et al., 2022",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#unnatural-instructions",
    "href": "slides/19_instruct-fine-tuning.html#unnatural-instructions",
    "title": "19. Instruct Fine-Tuning",
    "section": "Unnatural Instructions",
    "text": "Unnatural Instructions\n\nHonovich, et al., 2023",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#exemplars",
    "href": "slides/19_instruct-fine-tuning.html#exemplars",
    "title": "19. Instruct Fine-Tuning",
    "section": "Exemplars",
    "text": "Exemplars\n\nFlan 2022",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/19_instruct-fine-tuning.html#input-inversion",
    "href": "slides/19_instruct-fine-tuning.html#input-inversion",
    "title": "19. Instruct Fine-Tuning",
    "section": "Input Inversion",
    "text": "Input Inversion\n\n\n\nimprove task diversity with input inversion",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "19. Instruct Fine-Tuning"
    ]
  },
  {
    "objectID": "slides/18_mixture-of-experts.html#mixture-of-experts-the-basics",
    "href": "slides/18_mixture-of-experts.html#mixture-of-experts-the-basics",
    "title": "18. Mixture-of-Experts",
    "section": "Mixture-of-Experts: The Basics",
    "text": "Mixture-of-Experts: The Basics\n\nChapter 18 from GenAI Handbook\nGoal: Learn MoE for efficient LLMs\nKey idea: Use only some parameters per task\nBuilds on: Scaling laws, pretraining",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "18. Mixture-of-Experts"
    ]
  },
  {
    "objectID": "slides/18_mixture-of-experts.html#how-moe-works",
    "href": "slides/18_mixture-of-experts.html#how-moe-works",
    "title": "18. Mixture-of-Experts",
    "section": "How MoE Works",
    "text": "How MoE Works\n\nUnlike dense models (e.g., Llama3), MoE is sparse\nExperts: Specialized sub-networks per layer\nRouter: Picks a few experts per input\nResult: Big model, less compute",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "18. Mixture-of-Experts"
    ]
  },
  {
    "objectID": "slides/18_mixture-of-experts.html#mixture-of-experts",
    "href": "slides/18_mixture-of-experts.html#mixture-of-experts",
    "title": "18. Mixture-of-Experts",
    "section": "Mixture of Experts",
    "text": "Mixture of Experts",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "18. Mixture-of-Experts"
    ]
  },
  {
    "objectID": "slides/18_mixture-of-experts.html#why-it-matters",
    "href": "slides/18_mixture-of-experts.html#why-it-matters",
    "title": "18. Mixture-of-Experts",
    "section": "Why It Matters",
    "text": "Why It Matters\n\nEfficiency: Less memory/time than dense models\nScale: Grow “knowledge” without slowing down\nExamples: Mixtral (8x7B, 8x22B), maybe GPT-4",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "18. Mixture-of-Experts"
    ]
  },
  {
    "objectID": "slides/22_direct-preference-optimization-methods.html#learning-objectives",
    "href": "slides/22_direct-preference-optimization-methods.html#learning-objectives",
    "title": "22. Direct Preference Optimization Methods",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nContinue discussing fine tuning\nIntroduce Direct Preference Optimzation\nMove beyond RLHF\n\n\n\nI wish there was a concrete example of what DPO does",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "22. Direct Preference Optimization Methods"
    ]
  },
  {
    "objectID": "slides/22_direct-preference-optimization-methods.html#sources",
    "href": "slides/22_direct-preference-optimization-methods.html#sources",
    "title": "22. Direct Preference Optimization Methods",
    "section": "Sources",
    "text": "Sources\nFollowing the Gen AI Handbook, we looked at\n\nblog post by Matthew Gunton\nblog post by Kashif Rasul, et al. (Hugging Face), code",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "22. Direct Preference Optimization Methods"
    ]
  },
  {
    "objectID": "slides/22_direct-preference-optimization-methods.html#before-rlhf",
    "href": "slides/22_direct-preference-optimization-methods.html#before-rlhf",
    "title": "22. Direct Preference Optimization Methods",
    "section": "Before: RLHF",
    "text": "Before: RLHF\n\nRLHF\nimage source: Rafailov et al, 2024",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "22. Direct Preference Optimization Methods"
    ]
  },
  {
    "objectID": "slides/22_direct-preference-optimization-methods.html#now-dpo",
    "href": "slides/22_direct-preference-optimization-methods.html#now-dpo",
    "title": "22. Direct Preference Optimization Methods",
    "section": "Now: DPO",
    "text": "Now: DPO\n\nDPO\n“DPO removes the need for the rewards model all together!” — Matthew Gunton\nimage source: Rafailov et al, 2024",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "22. Direct Preference Optimization Methods"
    ]
  },
  {
    "objectID": "slides/22_direct-preference-optimization-methods.html#policy-iteration-1",
    "href": "slides/22_direct-preference-optimization-methods.html#policy-iteration-1",
    "title": "22. Direct Preference Optimization Methods",
    "section": "Policy Iteration",
    "text": "Policy Iteration\n\nDPO math\n\\(y_{w}\\) increases\npolicies improve\nimage source: Rafailov et al, 2024",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "22. Direct Preference Optimization Methods"
    ]
  },
  {
    "objectID": "slides/22_direct-preference-optimization-methods.html#motivations",
    "href": "slides/22_direct-preference-optimization-methods.html#motivations",
    "title": "22. Direct Preference Optimization Methods",
    "section": "Motivations",
    "text": "Motivations\n\nDPO on IMDb data set\nquality data: no need for reward model\ndynamic: update with new data\nprecise: can avoid certain topics\nimage source: Rafailov et al, 2024",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "22. Direct Preference Optimization Methods"
    ]
  },
  {
    "objectID": "slides/22_direct-preference-optimization-methods.html#newer-designs",
    "href": "slides/22_direct-preference-optimization-methods.html#newer-designs",
    "title": "22. Direct Preference Optimization Methods",
    "section": "Newer Designs",
    "text": "Newer Designs\n\nZephyr models\nimage source: Hugging Face",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "22. Direct Preference Optimization Methods"
    ]
  },
  {
    "objectID": "slides/45_distribution-modeling.html#slide",
    "href": "slides/45_distribution-modeling.html#slide",
    "title": "45. Distribution Modeling",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "45. Distribution Modeling"
    ]
  },
  {
    "objectID": "slides/45_distribution-modeling.html#slide-1",
    "href": "slides/45_distribution-modeling.html#slide-1",
    "title": "45. Distribution Modeling",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "45. Distribution Modeling"
    ]
  },
  {
    "objectID": "slides/45_distribution-modeling.html#slide-2",
    "href": "slides/45_distribution-modeling.html#slide-2",
    "title": "45. Distribution Modeling",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "45. Distribution Modeling"
    ]
  },
  {
    "objectID": "slides/45_distribution-modeling.html#slide-3",
    "href": "slides/45_distribution-modeling.html#slide-3",
    "title": "45. Distribution Modeling",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "45. Distribution Modeling"
    ]
  },
  {
    "objectID": "slides/53_vision-transformers.html#clip",
    "href": "slides/53_vision-transformers.html#clip",
    "title": "53. Vision Transformers",
    "section": "CLIP",
    "text": "CLIP\nContrastive Language Image Pre-Training\n\nCLIP architecture\nimage source: Chip Huyen",
    "crumbs": [
      "Section IX: Multimodal Models",
      "53. Vision Transformers"
    ]
  },
  {
    "objectID": "slides/53_vision-transformers.html#vision-neurons",
    "href": "slides/53_vision-transformers.html#vision-neurons",
    "title": "53. Vision Transformers",
    "section": "Vision Neurons",
    "text": "Vision Neurons\n\n\n\nvision neurons\n\n\n\n\n\nvision neurons\n\n\n\nimage source: dstill.pub",
    "crumbs": [
      "Section IX: Multimodal Models",
      "53. Vision Transformers"
    ]
  },
  {
    "objectID": "slides/53_vision-transformers.html#home",
    "href": "slides/53_vision-transformers.html#home",
    "title": "53. Vision Transformers",
    "section": "home",
    "text": "home\n\nreceipt bookkeeping\nimage source: Recycle This Pittsburgh\nscan grocery receipts\nOCR\nAI text decoding\ncode expense report",
    "crumbs": [
      "Section IX: Multimodal Models",
      "53. Vision Transformers"
    ]
  },
  {
    "objectID": "slides/53_vision-transformers.html#pedagogy",
    "href": "slides/53_vision-transformers.html#pedagogy",
    "title": "53. Vision Transformers",
    "section": "pedagogy",
    "text": "pedagogy\n\nCOPUS\nimage source: COPUS",
    "crumbs": [
      "Section IX: Multimodal Models",
      "53. Vision Transformers"
    ]
  },
  {
    "objectID": "slides/53_vision-transformers.html#software-dev",
    "href": "slides/53_vision-transformers.html#software-dev",
    "title": "53. Vision Transformers",
    "section": "software dev",
    "text": "software dev\nVision Question Answering\n\nVQA\nimage source: paper",
    "crumbs": [
      "Section IX: Multimodal Models",
      "53. Vision Transformers"
    ]
  },
  {
    "objectID": "slides/53_vision-transformers.html#comp-bio",
    "href": "slides/53_vision-transformers.html#comp-bio",
    "title": "53. Vision Transformers",
    "section": "comp bio",
    "text": "comp bio\ntransfer learning between RNA and ATAC sequencing\n\nscButterfly\nimage source: scButterfly",
    "crumbs": [
      "Section IX: Multimodal Models",
      "53. Vision Transformers"
    ]
  },
  {
    "objectID": "slides/53_vision-transformers.html#medicine",
    "href": "slides/53_vision-transformers.html#medicine",
    "title": "53. Vision Transformers",
    "section": "medicine",
    "text": "medicine\n\ndata types\nimage source: Science Direct",
    "crumbs": [
      "Section IX: Multimodal Models",
      "53. Vision Transformers"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#retrieval-augmented-generation",
    "href": "slides/29_retrieval-augmented-generation.html#retrieval-augmented-generation",
    "title": "29. Retrieval-Augmented Generation",
    "section": "Retrieval-Augmented Generation",
    "text": "Retrieval-Augmented Generation\nRAG is an application pattern for LLMS.\nIt uses information retrieval systems to give LLMs extra context.\nAllows the LLM to answer user queries not covered in its training data\n\nRAG",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#stages",
    "href": "slides/29_retrieval-augmented-generation.html#stages",
    "title": "29. Retrieval-Augmented Generation",
    "section": "Stages:",
    "text": "Stages:\n\nChunking: Turn your dataset into text documents and break it down into small pieces.\nEmbed documents: Turn each chunk into vectors representing their semantic meaning.\nVectorDB: Store embeddings in a vector database.\nRetrieval: Upon receiving a user query, retrieve chunks relevant to the user’s request.\nResponse Generation: Add chunks to the context and use the LLM.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#challenges-in-retrieval",
    "href": "slides/29_retrieval-augmented-generation.html#challenges-in-retrieval",
    "title": "29. Retrieval-Augmented Generation",
    "section": "Challenges in retrieval",
    "text": "Challenges in retrieval\n\nRecall: not all relevant chunks are retrieve.\nPrecision: not all chunks retrieved are relevant\nData: complex documents, semi-structured and unstructured data",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#query-transformations",
    "href": "slides/29_retrieval-augmented-generation.html#query-transformations",
    "title": "29. Retrieval-Augmented Generation",
    "section": "Query transformations",
    "text": "Query transformations\nHow can we make retrieval robust to variability in user input?\nApproaches:\n\nQuery expansion: decomposes the input into sub-questions.\nQuery re-writing: re-write user questions to improve retrieval.\nQuery compression: A chat conversation is compress into a final question for retrieval.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#query-construction",
    "href": "slides/29_retrieval-augmented-generation.html#query-construction",
    "title": "29. Retrieval-Augmented Generation",
    "section": "Query construction",
    "text": "Query construction\nWhere does the data live? what syntax is needed to query the data?\n\nQuery construction",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#the-retrieval-process",
    "href": "slides/29_retrieval-augmented-generation.html#the-retrieval-process",
    "title": "29. Retrieval-Augmented Generation",
    "section": "The retrieval process",
    "text": "The retrieval process\n\nIndexing: how do I desing the index in the vector database?\nChunk size: it controls how much information we load into the context window.\nDocument embedding strategy\nPost-processing: how to combine the documents that I have retrieved?",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#challenges-in-response",
    "href": "slides/29_retrieval-augmented-generation.html#challenges-in-response",
    "title": "29. Retrieval-Augmented Generation",
    "section": "Challenges in response",
    "text": "Challenges in response\nIn response synthesis.\n\nSafeguarding.\nTool use: tools used to assit the response generation.\n\nIn response evaluation.\n\nSynthetic dataset for evaluation\nLLMs as evaluators",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/29_retrieval-augmented-generation.html#section",
    "href": "slides/29_retrieval-augmented-generation.html#section",
    "title": "29. Retrieval-Augmented Generation",
    "section": "",
    "text": "In production RAG systems are a group of AI models, each playing its part in the workflow of data processing and response generation.\n\n\n\n\nRAG systems",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "29. Retrieval-Augmented Generation"
    ]
  },
  {
    "objectID": "slides/43_structured-state-space-models.html#slide",
    "href": "slides/43_structured-state-space-models.html#slide",
    "title": "43. Structured State Space Models",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "43. Structured State Space Models"
    ]
  },
  {
    "objectID": "slides/43_structured-state-space-models.html#slide-1",
    "href": "slides/43_structured-state-space-models.html#slide-1",
    "title": "43. Structured State Space Models",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "43. Structured State Space Models"
    ]
  },
  {
    "objectID": "slides/43_structured-state-space-models.html#slide-2",
    "href": "slides/43_structured-state-space-models.html#slide-2",
    "title": "43. Structured State Space Models",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "43. Structured State Space Models"
    ]
  },
  {
    "objectID": "slides/43_structured-state-space-models.html#slide-3",
    "href": "slides/43_structured-state-space-models.html#slide-3",
    "title": "43. Structured State Space Models",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "43. Structured State Space Models"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#textbook",
    "href": "slides/05_reinforcement-learning.html#textbook",
    "title": "5. Reinforcement Learning",
    "section": "Textbook",
    "text": "Textbook\n\n\n\n\n\nSutton and Barto\n\n\n\n\n\n\n\n\nMutual Information",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#markov-decision-process",
    "href": "slides/05_reinforcement-learning.html#markov-decision-process",
    "title": "5. Reinforcement Learning",
    "section": "Markov Decision Process",
    "text": "Markov Decision Process\n\nMDP",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#objective",
    "href": "slides/05_reinforcement-learning.html#objective",
    "title": "5. Reinforcement Learning",
    "section": "Objective",
    "text": "Objective\n\npolicy: \\(\\pi(a|s)\\)\nreturn: \\(G_{t} = \\sum_{k=t+1}^{T} \\gamma^{k-t-1}R_{k}\\)\nmaximize expected return over all policies\n\n\\[\\text{max}_{\\pi} \\text{E}_{\\pi}[G_{t}]\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#coupled-equations",
    "href": "slides/05_reinforcement-learning.html#coupled-equations",
    "title": "5. Reinforcement Learning",
    "section": "Coupled Equations",
    "text": "Coupled Equations\n\nstate value function\n\n\\[v_{\\pi}(s) = \\text{E}_{\\pi}[G_{t}|S_{t} = s]\\]\n\naction value function\n\n\\[q_{\\pi}(s,a) = \\text{E}_{\\pi}[G_{t}|S_{t} = s, A_{t} = a]\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#bellman-equations",
    "href": "slides/05_reinforcement-learning.html#bellman-equations",
    "title": "5. Reinforcement Learning",
    "section": "Bellman Equations",
    "text": "Bellman Equations\n\nconnect all state values\n\n\\[\\begin{array}{rcl}\n  v_{\\pi}(s^{i}) & = & \\text{E}_{\\pi}[G_{t}|s^{i}] \\\\\n  ~ & = & \\sum_{\\{a\\}} \\pi(a|s^{i}) \\cdot q(s^{i},a) \\\\\n  ~ & = & \\sum_{\\{a\\}} \\pi(a|s^{i}) \\cdot \\text{E}_{\\pi}[G_{t}|s^{i}, a] \\\\\n\\end{array}\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#bellman-optimality-equations",
    "href": "slides/05_reinforcement-learning.html#bellman-optimality-equations",
    "title": "5. Reinforcement Learning",
    "section": "Bellman Optimality Equations",
    "text": "Bellman Optimality Equations\nFor any optimal \\(\\pi_{*}\\), \\(\\forall s \\in S\\), \\(\\forall a \\in A\\)\n\\[\\begin{array}{rcl}\n  v_{*}(s) & = & \\text{max}_{a} q_{*}(s,a) \\\\\n  q_{*}(s,a) & = & \\sum_{s,r} p(s'r|s,a)[r + \\gamma v_{*}(s')] \\\\\n\\end{array}\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#monte-carlo-methods",
    "href": "slides/05_reinforcement-learning.html#monte-carlo-methods",
    "title": "5. Reinforcement Learning",
    "section": "Monte Carlo Methods",
    "text": "Monte Carlo Methods\nWe do not know \\(p(s'r|s,a)\\)\n\ngenerate samples: \\(S_{0}, A_{0}, R_{1}, S_{1}, A_{1}, R_{2}, ...\\)\nobtain averages \\(\\approx\\) expected values\ngeneralized policy iteration to obtain\n\n\\[\\pi \\approx \\pi_{*}\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#monte-carlo-evaluation",
    "href": "slides/05_reinforcement-learning.html#monte-carlo-evaluation",
    "title": "5. Reinforcement Learning",
    "section": "Monte Carlo Evaluation",
    "text": "Monte Carlo Evaluation\n\napprox \\(v_{\\pi}(s)\\)\n\n\\[\\text{E}_{\\pi}[G_{t}|S_{t} = s] \\approx \\frac{1}{C(s)}\\sum_{m=1}^{M}\\sum_{\\tau=0}^{T_{m}-1} I(s_{\\tau}^{m} = s)g_{\\tau}^{m}\\] * step size \\(\\alpha\\) for update rule\n\\[V(s_{t}^{m}) \\leftarrow V(s_{t}^{m}) + \\alpha\\left(g_{t}^{m} - V(s_{t}^{m})\\right)\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#exploration-exploitation-trade-off",
    "href": "slides/05_reinforcement-learning.html#exploration-exploitation-trade-off",
    "title": "5. Reinforcement Learning",
    "section": "Exploration-Exploitation Trade-Off",
    "text": "Exploration-Exploitation Trade-Off\n\nto discover optimal policies\n\n\nwe must explroe all state-action pairs\n\n\nto get high returns\n\n\nwe must exploit known high-value pairs",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#example-blackjack",
    "href": "slides/05_reinforcement-learning.html#example-blackjack",
    "title": "5. Reinforcement Learning",
    "section": "Example: Blackjack",
    "text": "Example: Blackjack\n\nMCMC solving blackjack gameimage credit: Mutual Information\n\n10 million games played",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#temporal-difference-learning",
    "href": "slides/05_reinforcement-learning.html#temporal-difference-learning",
    "title": "5. Reinforcement Learning",
    "section": "Temporal Difference Learning",
    "text": "Temporal Difference Learning\n\nMarkov Reward Process: A Markov decision process, but w/o actions\nMCMC requires an episode to complete before updating\n\n\nbut what if an episode is long?",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#n-step-td",
    "href": "slides/05_reinforcement-learning.html#n-step-td",
    "title": "5. Reinforcement Learning",
    "section": "n-step TD",
    "text": "n-step TD\nReplace \\(g_{t}^{m}\\) with\n\\[g_{t:t+n}^{m} = r_{t+1}^{m} + \\gamma r_{t+2}^{m} + \\cdots + \\gamma^{n-1} r_{t+n}^{m} + \\gamma_{n}V(s_{t+n}^{m})\\]\n\nupdates are applied during the episoes with an n-step delay",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#advantages",
    "href": "slides/05_reinforcement-learning.html#advantages",
    "title": "5. Reinforcement Learning",
    "section": "Advantages",
    "text": "Advantages\nCompared to MC, TD has\n\nbatch training\n\\(V(s)\\) do not depend on stepsize \\(\\alpha\\)\nmax likelihood of MRP (instead of min MSE)",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#q-learning",
    "href": "slides/05_reinforcement-learning.html#q-learning",
    "title": "5. Reinforcement Learning",
    "section": "Q-Learning",
    "text": "Q-Learning\n\\[r_{t+1}^{m} + \\gamma \\text{max}_{a} Q(s_{t+1}^{m},a)\\]\nupdates \\(Q\\) after each sarsa tuple (each n-step delay)",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#toward-continuity",
    "href": "slides/05_reinforcement-learning.html#toward-continuity",
    "title": "5. Reinforcement Learning",
    "section": "Toward Continuity",
    "text": "Toward Continuity\n\nprevious methods assumed tabular (discrete) and finite state spaces\nwithout “infinite data”, can we still generalize?\nfunction approximation: supervised learning + reinforcement learning",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#parameter-space",
    "href": "slides/05_reinforcement-learning.html#parameter-space",
    "title": "5. Reinforcement Learning",
    "section": "Parameter Space",
    "text": "Parameter Space\n\\[v_{\\pi}(s) \\approx \\hat{v}(s,w), \\quad w \\in \\mathbb{R}^{d}\\] * caution: updating \\(w\\) updates many values of \\(s\\)\n\nnot just the “visited states”",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#value-error",
    "href": "slides/05_reinforcement-learning.html#value-error",
    "title": "5. Reinforcement Learning",
    "section": "Value Error",
    "text": "Value Error\n\\[\\text{VE}(w) = \\sum_{s \\in S} \\mu(s)\\left[v_{\\pi}(s) - \\hat{v}(s,w)\\right]^{2}\\]\n\n\\(\\mu\\): distribution of states\nsolve with stochastic gradient descent\n\n\\[w \\leftarrow w + \\alpha\\left[U_{t} - \\hat{v}(S_{t},w)\\right] \\nabla \\hat{v}(S_{t},w)\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/05_reinforcement-learning.html#target-selection",
    "href": "slides/05_reinforcement-learning.html#target-selection",
    "title": "5. Reinforcement Learning",
    "section": "Target Selection",
    "text": "Target Selection\nTo find target \\(U_{t}\\)\n\nmay have multiple local minima\nestimates for state values may be biased\nemploy Semi-Gradient Temporal Difference",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "5. Reinforcement Learning"
    ]
  },
  {
    "objectID": "slides/33_mechanistic-interpretability.html#slide",
    "href": "slides/33_mechanistic-interpretability.html#slide",
    "title": "33. Mechanistic Interpretability",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "33. Mechanistic Interpretability"
    ]
  },
  {
    "objectID": "slides/33_mechanistic-interpretability.html#slide-1",
    "href": "slides/33_mechanistic-interpretability.html#slide-1",
    "title": "33. Mechanistic Interpretability",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "33. Mechanistic Interpretability"
    ]
  },
  {
    "objectID": "slides/33_mechanistic-interpretability.html#slide-2",
    "href": "slides/33_mechanistic-interpretability.html#slide-2",
    "title": "33. Mechanistic Interpretability",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "33. Mechanistic Interpretability"
    ]
  },
  {
    "objectID": "slides/33_mechanistic-interpretability.html#slide-3",
    "href": "slides/33_mechanistic-interpretability.html#slide-3",
    "title": "33. Mechanistic Interpretability",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "33. Mechanistic Interpretability"
    ]
  },
  {
    "objectID": "slides/23_context-scaling.html#learning-objectives",
    "href": "slides/23_context-scaling.html#learning-objectives",
    "title": "23. Context Scaling",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nAdapt to long context inputs\nReview RoPE\n\n\n\nnot a long section?",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "23. Context Scaling"
    ]
  },
  {
    "objectID": "slides/23_context-scaling.html#sources",
    "href": "slides/23_context-scaling.html#sources",
    "title": "23. Context Scaling",
    "section": "Sources",
    "text": "Sources\nFollowing the Gen AI Handbook, we looked at\n\nblog post by Belandros Pan (Hugging Face)\nblog post by Honglu Fan, et al. (Eleuther AI)\nblog post by Gradient",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "23. Context Scaling"
    ]
  },
  {
    "objectID": "slides/23_context-scaling.html#issues-with-long-contexts",
    "href": "slides/23_context-scaling.html#issues-with-long-contexts",
    "title": "23. Context Scaling",
    "section": "Issues with Long Contexts",
    "text": "Issues with Long Contexts\n\nbatch alignment\nmemory usage\nattention space: \\(O(N^{2})\\)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "23. Context Scaling"
    ]
  },
  {
    "objectID": "slides/23_context-scaling.html#fixes",
    "href": "slides/23_context-scaling.html#fixes",
    "title": "23. Context Scaling",
    "section": "Fixes",
    "text": "Fixes\n\nGrouped Query Attention (GQA): multiple query matrices, but shares keys and values\nGradient Checkpoint: only saves results only after \\(\\sqrt{N}\\) layers\nLoRA\nDistributed Training\nSample packing: sequences share long chains\nFlash Attention: \\(O(N)\\)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "23. Context Scaling"
    ]
  },
  {
    "objectID": "slides/23_context-scaling.html#rope",
    "href": "slides/23_context-scaling.html#rope",
    "title": "23. Context Scaling",
    "section": "RoPE",
    "text": "RoPE\n\nRoPE matrix\nPE vectors maintain magnitude\nresilient with test data \\(&gt;\\) training data\nimage credit: Eleuther AI",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "23. Context Scaling"
    ]
  },
  {
    "objectID": "slides/23_context-scaling.html#gradient",
    "href": "slides/23_context-scaling.html#gradient",
    "title": "23. Context Scaling",
    "section": "Gradient",
    "text": "Gradient\n\nH. Liu et al.: “1M-32K, 10M-131k, 10M-262k, 25M-524k, 50M-1048k (theta-context length) schedule”",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "23. Context Scaling"
    ]
  },
  {
    "objectID": "slides/23_context-scaling.html#llama-with-yarn",
    "href": "slides/23_context-scaling.html#llama-with-yarn",
    "title": "23. Context Scaling",
    "section": "Llama with YaRN",
    "text": "Llama with YaRN\n\nLlama with Yarn\nimage credit: Eleuther AI",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "23. Context Scaling"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#chapter-17-scaling-laws",
    "href": "slides/17_scaling-laws.html#chapter-17-scaling-laws",
    "title": "17. Scaling Laws",
    "section": "Chapter 17: Scaling Laws",
    "text": "Chapter 17: Scaling Laws\n\nGoal: Understand how scale predicts LLM performance\nBuilds on: Pretraining, Distributed Training\n\nWe’ll cover:\n\nWhat are scaling laws?\nPower laws: the foundation\nScaling laws in deep learning\nThe Chinchilla scaling law Implications and limitations\nThe “bitter lesson” of AI research",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#what-are-scaling-laws",
    "href": "slides/17_scaling-laws.html#what-are-scaling-laws",
    "title": "17. Scaling Laws",
    "section": "What Are Scaling Laws?",
    "text": "What Are Scaling Laws?\n\nScaling Laws describe how changes in model size, dataset size, or compute affect AI model performance.\nThey are essential for understanding and optimizing AI models.\nPredict how LLM performance (loss) changes with:\n\nModel size (parameters)\nDataset size (tokens)\nCompute (FLOPs)\n\nAllow us to make reliable predictions about model performance\nEnable optimization of hyperparameters without expensive grid searches",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#power-laws-the-foundation",
    "href": "slides/17_scaling-laws.html#power-laws-the-foundation",
    "title": "17. Scaling Laws",
    "section": "Power Laws: The Foundation",
    "text": "Power Laws: The Foundation\n\nPower laws: mathematical equations of the form: y = bx^a\nDescribe how one quantity varies as the power of another\n\ny : Performance (e.g., loss), x : Scale (e.g., parameters)\n\nOn a log-log plot, Power laws = straight lines",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#scaling-laws-in-deep-learning-why-scaling-laws-matter",
    "href": "slides/17_scaling-laws.html#scaling-laws-in-deep-learning-why-scaling-laws-matter",
    "title": "17. Scaling Laws",
    "section": "Scaling Laws in Deep Learning: why scaling laws matter",
    "text": "Scaling Laws in Deep Learning: why scaling laws matter\n\nIn deep learning, performance scales according to:\n\nN: Model size (number of parameters)\nD: Dataset size (tokens, pixels, etc.)\nC: Compute (FLOPs)\n\nAs these variables increase, model loss decreases following power laws\nScaling is primarily bottlenecked by computational resources",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#key-variables-in-scaling-laws",
    "href": "slides/17_scaling-laws.html#key-variables-in-scaling-laws",
    "title": "17. Scaling Laws",
    "section": "Key Variables in Scaling Laws",
    "text": "Key Variables in Scaling Laws\n\nModel Size (N):\nNumber of parameters (weights) in the model\nMeasures model capacity\nDataset Size (D):\nNumber of tokens the model is trained on\nTokens can be words, subwords, pixels, etc.\nCompute (C):\nFloating point operations (FLOPs) used during training\nEnables both larger models and more training data",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#the-chinchilla-scaling-law",
    "href": "slides/17_scaling-laws.html#the-chinchilla-scaling-law",
    "title": "17. Scaling Laws",
    "section": "The Chinchilla Scaling Law",
    "text": "The Chinchilla Scaling Law\n\nKey paper (Hoffmann et al. 2022): “Training Compute-Optimal LLMs”\nFinding: Balance model size & data for compute budget\nIntroduced by Hoffmann et al. (2022)\n\n\n\nKey insight: optimal performance requires balancing model and data size\n\n\n\nSmall models with more training data can outperform larger models\nChinchilla (70B params) beat larger models with more tokens",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#chinchilla-in-action",
    "href": "slides/17_scaling-laws.html#chinchilla-in-action",
    "title": "17. Scaling Laws",
    "section": "Chinchilla in Action",
    "text": "Chinchilla in Action",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#implications",
    "href": "slides/17_scaling-laws.html#implications",
    "title": "17. Scaling Laws",
    "section": "Implications",
    "text": "Implications\n\nPlanning: Predict performance before training\nEfficiency: Avoid oversized models\nCost: Optimize compute allocation\nTies to distributed training’s scale (Ch. 16)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#universal-applicability",
    "href": "slides/17_scaling-laws.html#universal-applicability",
    "title": "17. Scaling Laws",
    "section": "Universal Applicability",
    "text": "Universal Applicability\n\nScaling laws hold across many modalities and orders of magnitude.\nGenerative models (e.g., LLMs) follow scaling laws.\nStrong for generative models (e.g., LLMs)\nWeaker for discriminative models (e.g., image classifiers)\nAlgorithms can shift the curve (better constant terms)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#the-bitter-lesson",
    "href": "slides/17_scaling-laws.html#the-bitter-lesson",
    "title": "17. Scaling Laws",
    "section": "The Bitter Lesson",
    "text": "The Bitter Lesson\n\nKey observation: Scaling beats intricate, expert-designed systems.\nSimpler systems trained on more data outperform complex, human-designed approaches.\nLesson: Invest in compute and data rather than manual feature engineering.\nScaling often beats complex designs\n“More compute + data &gt; human ingenuity alone” (Sutton)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#challenges-debates",
    "href": "slides/17_scaling-laws.html#challenges-debates",
    "title": "17. Scaling Laws",
    "section": "Challenges & Debates",
    "text": "Challenges & Debates\n\nChinchilla’s exact numbers contested\nScaling laws are not universal.\nEquations are debated and subject to refinement.\nFuture trends: Scaling laws may evolve as models and tasks become more complex.\nReplication issues (see Eleuther AI post)\nFuture laws may refine predictions",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#implications-for-ai-development",
    "href": "slides/17_scaling-laws.html#implications-for-ai-development",
    "title": "17. Scaling Laws",
    "section": "Implications for AI Development",
    "text": "Implications for AI Development\n\nResource allocation: Optimize the ratio of model size to dataset size\nInvestment focus: Compute is the fundamental bottleneck\nResearch priorities: Algorithm improvements can shift the scaling curve\nFuture capabilities: May be predictable through extrapolation\nAI timelines: Scaling laws inform predictions about AI progress",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#key-takeaways",
    "href": "slides/17_scaling-laws.html#key-takeaways",
    "title": "17. Scaling Laws",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nScaling laws predict loss via params, data, compute\nChinchilla: Balance scale for efficiency\nPower laws = reliable trends, but not universal\nOptimize training smarter, not harder",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#resources",
    "href": "slides/17_scaling-laws.html#resources",
    "title": "17. Scaling Laws",
    "section": "Resources",
    "text": "Resources\n\n“Chinchilla Scaling Laws” by Rania Hossam\n“Chinchilla’s Wild Implications” (LessWrong)\n“Scaling Laws and Emergent Properties” by Clément Thiriet\nStanford CS224n “Scaling Language Models” video",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/17_scaling-laws.html#qa",
    "href": "slides/17_scaling-laws.html#qa",
    "title": "17. Scaling Laws",
    "section": "Q&A",
    "text": "Q&A\n\n\n\n\n\n\nTrue or False: Scaling laws apply to all ML models\n\n\nFalse. Generative models (e.g., LLMs) follow clear scaling laws, but discriminative models (e.g., image classifiers) often don’t.\n\n\n\n\n\n\n\n\n\nHow does compute relate to scaling?\n\n\nCompute drives scaling by enabling larger models and datasets. More FLOPs = more parameters or tokens.\n\n\n\n\n\n\n\n\n\nWhat’s a power law?\n\n\nA power law is ( y = bx^a ), where ( y ) (e.g., loss) scales with ( x ) (e.g., params) raised to an exponent. It’s linear on a log-log plot.",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "17. Scaling Laws"
    ]
  },
  {
    "objectID": "slides/40_sliding-window-attention.html#slide",
    "href": "slides/40_sliding-window-attention.html#slide",
    "title": "40. Sliding Window Attention",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "40. Sliding Window Attention"
    ]
  },
  {
    "objectID": "slides/40_sliding-window-attention.html#slide-1",
    "href": "slides/40_sliding-window-attention.html#slide-1",
    "title": "40. Sliding Window Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "40. Sliding Window Attention"
    ]
  },
  {
    "objectID": "slides/40_sliding-window-attention.html#slide-2",
    "href": "slides/40_sliding-window-attention.html#slide-2",
    "title": "40. Sliding Window Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "40. Sliding Window Attention"
    ]
  },
  {
    "objectID": "slides/40_sliding-window-attention.html#slide-3",
    "href": "slides/40_sliding-window-attention.html#slide-3",
    "title": "40. Sliding Window Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "40. Sliding Window Attention"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#palmer-penguins",
    "href": "slides/20_low-rank-adapters-lora.html#palmer-penguins",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "Palmer Penguins",
    "text": "Palmer Penguins\n\nAllison Horst",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#svd",
    "href": "slides/20_low-rank-adapters-lora.html#svd",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "SVD",
    "text": "SVD\n\nSVD\nimage source: Antriksh Singh",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#update-rule",
    "href": "slides/20_low-rank-adapters-lora.html#update-rule",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "Update Rule",
    "text": "Update Rule\n\\[\\begin{array}{rcl}\n  W_{1} & = & W_{\\text{pre}} + \\Delta W_{0} \\\\\n  W_{2} & = & W_{1} + \\Delta W_{1} \\\\\n  W_{3} & = & W_{2} + \\Delta W_{2} \\\\\n  ... & ~ & ... \\\\\n  W_{\\text{out}}\n\\end{array}\\]",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#freezing-the-pre-training-weights",
    "href": "slides/20_low-rank-adapters-lora.html#freezing-the-pre-training-weights",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "Freezing the Pre-Training Weights",
    "text": "Freezing the Pre-Training Weights\n\\[W_{\\text{out}} = W_{\\text{pre}} + \\displaystyle\\sum_{i = 0} \\Delta W_{i}\\]",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#fine-tuning",
    "href": "slides/20_low-rank-adapters-lora.html#fine-tuning",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "Fine Tuning",
    "text": "Fine Tuning\n\nfine tuning scheme\nimage source: Sebastian Raschka",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#dimensionality-reduction",
    "href": "slides/20_low-rank-adapters-lora.html#dimensionality-reduction",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nmatrix factorization\nimage source: Sebastian Raschka",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#speed-versus-complexity-trade-off",
    "href": "slides/20_low-rank-adapters-lora.html#speed-versus-complexity-trade-off",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "Speed versus Complexity Trade-Off",
    "text": "Speed versus Complexity Trade-Off\n\nsmaller rank \\(r\\)\n\nfewer parameters\nfaster training\nlower compute\n\nlarger rank \\(r\\)\n\nmore likely to capture task-specific information",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#dora-from-vectors",
    "href": "slides/20_low-rank-adapters-lora.html#dora-from-vectors",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "DoRA from Vectors",
    "text": "DoRA from Vectors\nWeight-Decomposed Low-Rank Adaptation\n\n\\(m\\): magnitude vector\n\\(V\\): directional matrix\n\n\nvectors!",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#dora-decomposition",
    "href": "slides/20_low-rank-adapters-lora.html#dora-decomposition",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "DoRA Decomposition",
    "text": "DoRA Decomposition\n\\[W' = m \\cdot \\frac{W_{0} + BA}{||W_{0} + BA||_{c}}\\]\n\nDoRA decomposition",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/20_low-rank-adapters-lora.html#dora-workflow",
    "href": "slides/20_low-rank-adapters-lora.html#dora-workflow",
    "title": "20. Low-Rank Adapters (LoRA)",
    "section": "DoRA Workflow",
    "text": "DoRA Workflow\n\nDoRA workflow\nimages source: Sebastian Raschka",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "20. Low-Rank Adapters (LoRA)"
    ]
  },
  {
    "objectID": "slides/34_linear-representation-hypotheses.html#slide",
    "href": "slides/34_linear-representation-hypotheses.html#slide",
    "title": "34. Linear Representation Hypotheses",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "34. Linear Representation Hypotheses"
    ]
  },
  {
    "objectID": "slides/34_linear-representation-hypotheses.html#slide-1",
    "href": "slides/34_linear-representation-hypotheses.html#slide-1",
    "title": "34. Linear Representation Hypotheses",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "34. Linear Representation Hypotheses"
    ]
  },
  {
    "objectID": "slides/34_linear-representation-hypotheses.html#slide-2",
    "href": "slides/34_linear-representation-hypotheses.html#slide-2",
    "title": "34. Linear Representation Hypotheses",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "34. Linear Representation Hypotheses"
    ]
  },
  {
    "objectID": "slides/34_linear-representation-hypotheses.html#slide-3",
    "href": "slides/34_linear-representation-hypotheses.html#slide-3",
    "title": "34. Linear Representation Hypotheses",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "34. Linear Representation Hypotheses"
    ]
  },
  {
    "objectID": "slides/06_markov-models.html#tabular-state-space",
    "href": "slides/06_markov-models.html#tabular-state-space",
    "title": "6. Markov Models",
    "section": "Tabular State Space",
    "text": "Tabular State Space\n\nfairy tale generatorimage credit: Aja Hammerly",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "6. Markov Models"
    ]
  },
  {
    "objectID": "slides/06_markov-models.html#trajectories",
    "href": "slides/06_markov-models.html#trajectories",
    "title": "6. Markov Models",
    "section": "Trajectories",
    "text": "Trajectories\n\nonce, upon, a, time, a, bird, and, a, mouse\n\n\na, sausage, entered, into, a, partnership, and, set\n\n\nbird, a, and, set, up, house, together",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "6. Markov Models"
    ]
  },
  {
    "objectID": "slides/06_markov-models.html#markov-property",
    "href": "slides/06_markov-models.html#markov-property",
    "title": "6. Markov Models",
    "section": "Markov Property",
    "text": "Markov Property\nThe future of a stochastic process is independent of its past\n\\[P(X_{t+1} = x|X_{t}, X_{t-1}, ..., X_{t-k}) = P(X_{t+1} = x|X_{t})\\] * memoryless property",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "6. Markov Models"
    ]
  },
  {
    "objectID": "slides/06_markov-models.html#metropolis-hastings",
    "href": "slides/06_markov-models.html#metropolis-hastings",
    "title": "6. Markov Models",
    "section": "Metropolis-Hastings",
    "text": "Metropolis-Hastings\n\nMetropolis-Hastings Algorithm",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "6. Markov Models"
    ]
  },
  {
    "objectID": "slides/06_markov-models.html#markov-chain-monte-carlo",
    "href": "slides/06_markov-models.html#markov-chain-monte-carlo",
    "title": "6. Markov Models",
    "section": "Markov Chain Monte Carlo",
    "text": "Markov Chain Monte Carlo\n\n\n\nMCMC to posterior dist",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "6. Markov Models"
    ]
  },
  {
    "objectID": "slides/42_linear-attention-rwkv.html#slide",
    "href": "slides/42_linear-attention-rwkv.html#slide",
    "title": "42. Linear Attention (RWKV)",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "42. Linear Attention (RWKV)"
    ]
  },
  {
    "objectID": "slides/42_linear-attention-rwkv.html#slide-1",
    "href": "slides/42_linear-attention-rwkv.html#slide-1",
    "title": "42. Linear Attention (RWKV)",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "42. Linear Attention (RWKV)"
    ]
  },
  {
    "objectID": "slides/42_linear-attention-rwkv.html#slide-2",
    "href": "slides/42_linear-attention-rwkv.html#slide-2",
    "title": "42. Linear Attention (RWKV)",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "42. Linear Attention (RWKV)"
    ]
  },
  {
    "objectID": "slides/42_linear-attention-rwkv.html#slide-3",
    "href": "slides/42_linear-attention-rwkv.html#slide-3",
    "title": "42. Linear Attention (RWKV)",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "42. Linear Attention (RWKV)"
    ]
  },
  {
    "objectID": "slides/46_variational-auto-encoders.html#slide",
    "href": "slides/46_variational-auto-encoders.html#slide",
    "title": "46. Variational Auto-Encoders",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "46. Variational Auto-Encoders"
    ]
  },
  {
    "objectID": "slides/46_variational-auto-encoders.html#slide-1",
    "href": "slides/46_variational-auto-encoders.html#slide-1",
    "title": "46. Variational Auto-Encoders",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "46. Variational Auto-Encoders"
    ]
  },
  {
    "objectID": "slides/46_variational-auto-encoders.html#slide-2",
    "href": "slides/46_variational-auto-encoders.html#slide-2",
    "title": "46. Variational Auto-Encoders",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "46. Variational Auto-Encoders"
    ]
  },
  {
    "objectID": "slides/46_variational-auto-encoders.html#slide-3",
    "href": "slides/46_variational-auto-encoders.html#slide-3",
    "title": "46. Variational Auto-Encoders",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "46. Variational Auto-Encoders"
    ]
  },
  {
    "objectID": "slides/04_online-learning-and-regret-minimization.html#online-convex-optimization",
    "href": "slides/04_online-learning-and-regret-minimization.html#online-convex-optimization",
    "title": "4. Online Learning and Regret Minimization",
    "section": "Online Convex Optimization",
    "text": "Online Convex Optimization\n\nOCO",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "4. Online Learning and Regret Minimization"
    ]
  },
  {
    "objectID": "slides/04_online-learning-and-regret-minimization.html#regret",
    "href": "slides/04_online-learning-and-regret-minimization.html#regret",
    "title": "4. Online Learning and Regret Minimization",
    "section": "Regret",
    "text": "Regret\n\\[\\text{Regret}_{T}(A) = \\text{sup}\\left[\\sum_{t=1}^{T}f_{t}(x_{t}^{A}) - \\text{min}_{x}\\sum_{t=1}^{T}f_{t}(x)\\right]\\]\n\n\\(\\vec{x}_{t}^{A}\\): player actions of an algorithm in a decision set\n\\(T\\): number of game iterations",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "4. Online Learning and Regret Minimization"
    ]
  },
  {
    "objectID": "slides/04_online-learning-and-regret-minimization.html#applications",
    "href": "slides/04_online-learning-and-regret-minimization.html#applications",
    "title": "4. Online Learning and Regret Minimization",
    "section": "Applications",
    "text": "Applications\n\nspam filtering\npath finding\nportfolio selection\nrecommendation systems",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "4. Online Learning and Regret Minimization"
    ]
  },
  {
    "objectID": "slides/04_online-learning-and-regret-minimization.html#experts-and-adversaries",
    "href": "slides/04_online-learning-and-regret-minimization.html#experts-and-adversaries",
    "title": "4. Online Learning and Regret Minimization",
    "section": "Experts and Adversaries",
    "text": "Experts and Adversaries\nTheorem 1.2 Let \\(\\epsilon\\in(0,0.5)\\). Suppose that the best expert makes \\(L\\) mistakes. Then:\n\n\\(\\exists\\) an efficient deterministic algorithm \\(&lt; 2(1+\\epsilon)L + \\frac{2\\log N}{\\epsilon}\\) mistakes\n\\(\\exists\\) an efficient randomized algorithm \\(\\leq (1+\\epsilon)L + \\frac{\\log N}{\\epsilon}\\) mistakes",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "4. Online Learning and Regret Minimization"
    ]
  },
  {
    "objectID": "slides/04_online-learning-and-regret-minimization.html#weighted-majority-algorithm",
    "href": "slides/04_online-learning-and-regret-minimization.html#weighted-majority-algorithm",
    "title": "4. Online Learning and Regret Minimization",
    "section": "Weighted Majority Algorithm",
    "text": "Weighted Majority Algorithm\n\npredict according to majority of experts\n\n\\[a_{t} = \\begin{cases} A, & W_{t}(A) \\geq W_{t}(B) \\\\ B, & \\text{otherwise}\\end{cases}\\]\n\nupdate weights\n\n\\[W_{t+1}(i) = \\begin{cases}W_{t}(i), & \\text{if expert i was correct} \\\\ W_{t}(i)(1-\\epsilon), & \\text{if expert i was wrong}\\end{cases}\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "4. Online Learning and Regret Minimization"
    ]
  },
  {
    "objectID": "slides/04_online-learning-and-regret-minimization.html#hedging",
    "href": "slides/04_online-learning-and-regret-minimization.html#hedging",
    "title": "4. Online Learning and Regret Minimization",
    "section": "Hedging",
    "text": "Hedging\n\\[W_{t+1}(i) = W_{t}(i)e^{-\\epsilon \\ell_{t}(i)}\\]\n\n\\(\\epsilon\\): learning rate\n\\(\\ell_{t}(i)\\): loss by expert \\(i\\) at iteration \\(t\\)",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "4. Online Learning and Regret Minimization"
    ]
  },
  {
    "objectID": "slides/00-club_intro.html#book-club-meetings",
    "href": "slides/00-club_intro.html#book-club-meetings",
    "title": "Club Meetings",
    "section": "Book club meetings",
    "text": "Book club meetings\n\nVolunteer leads discussion of a chapter\n\nThis is the best way to learn the material.\n\nPresentations:\n\nReview of material\nQuestions you have\nMaybe live demo\n\nMore info about editing: this github repo.\nRecorded, available on the Data Science Learning Community YouTube Channel (DSLC.video).",
    "crumbs": [
      "Club Meetings"
    ]
  },
  {
    "objectID": "slides/00-club_intro.html#pace",
    "href": "slides/00-club_intro.html#pace",
    "title": "Club Meetings",
    "section": "Pace",
    "text": "Pace\n\nGoal: 3 chapters/week\nOk to split overwhelming chapters\nOk to combine short chapters\nMeet every week except holidays, etc\n\nIdeally can discuss even if presenter unavailable",
    "crumbs": [
      "Club Meetings"
    ]
  },
  {
    "objectID": "slides/00-club_intro.html#learning-objectives-los",
    "href": "slides/00-club_intro.html#learning-objectives-los",
    "title": "Club Meetings",
    "section": "Learning objectives (LOs)",
    "text": "Learning objectives (LOs)\n\nStudents who study with LOs in mind retain more.\nTips:\n\n“After today’s session, you will be able to…”\nVery roughly 1 per section.",
    "crumbs": [
      "Club Meetings"
    ]
  },
  {
    "objectID": "slides/44_hyperattention.html#slide",
    "href": "slides/44_hyperattention.html#slide",
    "title": "44. HyperAttention",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "44. HyperAttention"
    ]
  },
  {
    "objectID": "slides/44_hyperattention.html#slide-1",
    "href": "slides/44_hyperattention.html#slide-1",
    "title": "44. HyperAttention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "44. HyperAttention"
    ]
  },
  {
    "objectID": "slides/44_hyperattention.html#slide-2",
    "href": "slides/44_hyperattention.html#slide-2",
    "title": "44. HyperAttention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "44. HyperAttention"
    ]
  },
  {
    "objectID": "slides/44_hyperattention.html#slide-3",
    "href": "slides/44_hyperattention.html#slide-3",
    "title": "44. HyperAttention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "44. HyperAttention"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#long-short-term-memory-nets",
    "href": "slides/09_lstms-and-grus.html#long-short-term-memory-nets",
    "title": "9. LSTMs and GRUs",
    "section": "Long Short-Term Memory nets",
    "text": "Long Short-Term Memory nets\n\nA special kind of RNNs capable of learning long-term dependencies (no vanishing gradient)\nInvented by Hochreiter and Schmidhuber in 1995. LSTMs became the default choice for RNN architecture.\n\nIf we would like to predict the words in orange:\n\nAlice is allergic to nuts. (…). She can’t eat peanut butter.\n\nIf there were many sentences in (…), the context might get lost in a standard RNN.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#lstms-structure",
    "href": "slides/09_lstms-and-grus.html#lstms-structure",
    "title": "9. LSTMs and GRUs",
    "section": "LSTMs structure",
    "text": "LSTMs structure\n\nA chain-like structure just like RNNs.\n4 modules instead of a single hidden layer: the cell state, the forget gate layer, the input gate layer, and the output gate.\n\n\n\n\nLSTM structure",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#sigmoid-and-tanh",
    "href": "slides/09_lstms-and-grus.html#sigmoid-and-tanh",
    "title": "9. LSTMs and GRUs",
    "section": "Sigmoid and tanh",
    "text": "Sigmoid and tanh\n\n\n\nSigmoid and tanh\n\n\n\n\n\\[\\sigma(z)=\\frac{1}{1+e^{-z}}\\]\n\n\\[\\text{tanh}(z)=\\frac{e^z-e^{-z}}{e^z+e^{-z}}\\]",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#the-cell-state",
    "href": "slides/09_lstms-and-grus.html#the-cell-state",
    "title": "9. LSTMs and GRUs",
    "section": "The cell state",
    "text": "The cell state\nThe cell state represents the Long-Term Memory\nIt passes vectors without weights.\nLSTM can remove or add information to the cell state\n\nLSTM cell state",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#the-forget-gate-layer",
    "href": "slides/09_lstms-and-grus.html#the-forget-gate-layer",
    "title": "9. LSTMs and GRUs",
    "section": "The forget gate layer",
    "text": "The forget gate layer\n\nLSTM forget gateTo decide what information we’re keeping from the previous output. It uses a sigmoid function:\n\n0 completely forget this\n1 completely keep this.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#input-gate-layer",
    "href": "slides/09_lstms-and-grus.html#input-gate-layer",
    "title": "9. LSTMs and GRUs",
    "section": "Input gate layer",
    "text": "Input gate layer\nIt decides which values we’ll update:\n\nThe tanh layer creates a vector of new candidate values, a potential memory to add to the long-term memory\nThe \\(\\sigma\\) layer decides the percentage of the potential memory to be added to the state.\n\n\nLSTM input gate",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#update-the-cell-state",
    "href": "slides/09_lstms-and-grus.html#update-the-cell-state",
    "title": "9. LSTMs and GRUs",
    "section": "Update the cell state",
    "text": "Update the cell state\n\nWe forget the things we decided to forget and add the candidate values, scaled by how much we decided to update each state value.\n\n\nLSTM update cell state",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#the-output-gate",
    "href": "slides/09_lstms-and-grus.html#the-output-gate",
    "title": "9. LSTMs and GRUs",
    "section": "The output gate",
    "text": "The output gate\nIt is based on our cell state, but with a filtered version to create a potential new short term memory\nAgain, a tanh and a \\(\\sigma\\) to decide what to update and by how much.\n\nLSTM output gate",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/09_lstms-and-grus.html#gated-recurrent-unit",
    "href": "slides/09_lstms-and-grus.html#gated-recurrent-unit",
    "title": "9. LSTMs and GRUs",
    "section": "Gated Recurrent Unit",
    "text": "Gated Recurrent Unit\n\n\nA variation of the LSTM with two gates:\n\nreset gate: how much of the previous state we want to remember\nupdate gate: how much of the new state we’ll copy to the old one\n\n\n\n\n\nGRUs\n\n\n\nIntroduced in 2014, as a simplification of LSTMs, with fewer parameters.\nNo performance difference between SLTM and GRU",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "9. LSTMs and GRUs"
    ]
  },
  {
    "objectID": "slides/35_parameter-quantization.html#slide",
    "href": "slides/35_parameter-quantization.html#slide",
    "title": "35. Parameter Quantization",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "35. Parameter Quantization"
    ]
  },
  {
    "objectID": "slides/35_parameter-quantization.html#slide-1",
    "href": "slides/35_parameter-quantization.html#slide-1",
    "title": "35. Parameter Quantization",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "35. Parameter Quantization"
    ]
  },
  {
    "objectID": "slides/35_parameter-quantization.html#slide-2",
    "href": "slides/35_parameter-quantization.html#slide-2",
    "title": "35. Parameter Quantization",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "35. Parameter Quantization"
    ]
  },
  {
    "objectID": "slides/35_parameter-quantization.html#slide-3",
    "href": "slides/35_parameter-quantization.html#slide-3",
    "title": "35. Parameter Quantization",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "35. Parameter Quantization"
    ]
  },
  {
    "objectID": "slides/38_key-value-caching-and-paged-attention.html#slide",
    "href": "slides/38_key-value-caching-and-paged-attention.html#slide",
    "title": "38. Key-Value Caching and Paged Attention",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "38. Key-Value Caching and Paged Attention"
    ]
  },
  {
    "objectID": "slides/38_key-value-caching-and-paged-attention.html#slide-1",
    "href": "slides/38_key-value-caching-and-paged-attention.html#slide-1",
    "title": "38. Key-Value Caching and Paged Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "38. Key-Value Caching and Paged Attention"
    ]
  },
  {
    "objectID": "slides/38_key-value-caching-and-paged-attention.html#slide-2",
    "href": "slides/38_key-value-caching-and-paged-attention.html#slide-2",
    "title": "38. Key-Value Caching and Paged Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "38. Key-Value Caching and Paged Attention"
    ]
  },
  {
    "objectID": "slides/38_key-value-caching-and-paged-attention.html#slide-3",
    "href": "slides/38_key-value-caching-and-paged-attention.html#slide-3",
    "title": "38. Key-Value Caching and Paged Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "38. Key-Value Caching and Paged Attention"
    ]
  },
  {
    "objectID": "slides/32_representation-engineering.html#slide",
    "href": "slides/32_representation-engineering.html#slide",
    "title": "32. Representation Engineering",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "32. Representation Engineering"
    ]
  },
  {
    "objectID": "slides/32_representation-engineering.html#slide-1",
    "href": "slides/32_representation-engineering.html#slide-1",
    "title": "32. Representation Engineering",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "32. Representation Engineering"
    ]
  },
  {
    "objectID": "slides/32_representation-engineering.html#slide-2",
    "href": "slides/32_representation-engineering.html#slide-2",
    "title": "32. Representation Engineering",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "32. Representation Engineering"
    ]
  },
  {
    "objectID": "slides/32_representation-engineering.html#slide-3",
    "href": "slides/32_representation-engineering.html#slide-3",
    "title": "32. Representation Engineering",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "32. Representation Engineering"
    ]
  },
  {
    "objectID": "slides/41_ring-attention.html#slide",
    "href": "slides/41_ring-attention.html#slide",
    "title": "41. Ring Attention",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "41. Ring Attention"
    ]
  },
  {
    "objectID": "slides/41_ring-attention.html#slide-1",
    "href": "slides/41_ring-attention.html#slide-1",
    "title": "41. Ring Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "41. Ring Attention"
    ]
  },
  {
    "objectID": "slides/41_ring-attention.html#slide-2",
    "href": "slides/41_ring-attention.html#slide-2",
    "title": "41. Ring Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "41. Ring Attention"
    ]
  },
  {
    "objectID": "slides/41_ring-attention.html#slide-3",
    "href": "slides/41_ring-attention.html#slide-3",
    "title": "41. Ring Attention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VII: Sub-Quadratic Context Scaling",
      "41. Ring Attention"
    ]
  },
  {
    "objectID": "slides/08_recurrent-neural-networks.html#why-do-we-need-them",
    "href": "slides/08_recurrent-neural-networks.html#why-do-we-need-them",
    "title": "8. Recurrent Neural Networks",
    "section": "Why do we need them?",
    "text": "Why do we need them?\n\nVanilla Neural Networks have fixed-sized vector as input and produce a fixed-sized vector as output. They assume inputs and outputs are independent.\nRecurrent neural nets allow us to operate over sequences of vectors: sequences in the input, the output, or both.\n\n\n\nSequence input/output\n\n\n\nExamples:\n(1) Vanilla. (2) Image to sentence of words. (3) Sentence to classification. (4) Sentence translation. (5) Video frames to labeled frames.\n\nThey are trained on sequential or time series data where prior elements affect the next output.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "8. Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "slides/08_recurrent-neural-networks.html#rnns-structure",
    "href": "slides/08_recurrent-neural-networks.html#rnns-structure",
    "title": "8. Recurrent Neural Networks",
    "section": "RNNs structure",
    "text": "RNNs structure\nRecurrent connections: the output of a neuron at one time step is fed back as input to the network at the next time step.\n\n\nRecurrent unit (v): a single hidden vector updated at each time step.\n\n\n\n\nRNN structure\n\n\n\nThe recurrent unit serves as a form of memory that is based on the current input and the previous hidden state.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "8. Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "slides/08_recurrent-neural-networks.html#section",
    "href": "slides/08_recurrent-neural-networks.html#section",
    "title": "8. Recurrent Neural Networks",
    "section": "",
    "text": "RNN Example from StatQuest",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "8. Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "slides/08_recurrent-neural-networks.html#limitations",
    "href": "slides/08_recurrent-neural-networks.html#limitations",
    "title": "8. Recurrent Neural Networks",
    "section": "Limitations",
    "text": "Limitations\n\n\nWeights in the recurrent vector are uptated with backpropagation.\nPartial derivatives cause gradients of earlier weights to be calculated with increasingly many multiplications.\n\nVanishing Gradient: If \\(w_r &lt; 1\\) gradients shrinks over time steps, limiting the ability to learn long-term dependencies.\nExploding Gradient: If \\(w_r &gt; 1\\) gradients grow uncontrollably, causing large weight updates that destabilize training.\n\n\n\n\n\nExploding Gradient",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "8. Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "slides/11_encoders-and-decoders.html#slide",
    "href": "slides/11_encoders-and-decoders.html#slide",
    "title": "11. Encoders and Decoders",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "11. Encoders and Decoders"
    ]
  },
  {
    "objectID": "slides/11_encoders-and-decoders.html#slide-1",
    "href": "slides/11_encoders-and-decoders.html#slide-1",
    "title": "11. Encoders and Decoders",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "11. Encoders and Decoders"
    ]
  },
  {
    "objectID": "slides/11_encoders-and-decoders.html#slide-2",
    "href": "slides/11_encoders-and-decoders.html#slide-2",
    "title": "11. Encoders and Decoders",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "11. Encoders and Decoders"
    ]
  },
  {
    "objectID": "slides/11_encoders-and-decoders.html#slide-3",
    "href": "slides/11_encoders-and-decoders.html#slide-3",
    "title": "11. Encoders and Decoders",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "11. Encoders and Decoders"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#learning-objectives",
    "href": "slides/21_reward-models-and-rlhf.html#learning-objectives",
    "title": "21. Reward Models and RLHF",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nContinue discussing fine tuning\nMotivate reward models\nElaborate on RLHF’s role in AI history\n\n\n\nIf this book club is repeated in the future, readers might be even less interested in benchmarks from a few years ago",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#sources",
    "href": "slides/21_reward-models-and-rlhf.html#sources",
    "title": "21. Reward Models and RLHF",
    "section": "Sources",
    "text": "Sources\nFollowing the Gen AI Handbook, we looked at\n\nblog post by Chip Huyen (author)\nblog post by Nathan Lambert, et al. (Hugging Face)\nblog post by Sebastian Raschka (author)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#continued-pre-training",
    "href": "slides/21_reward-models-and-rlhf.html#continued-pre-training",
    "title": "21. Reward Models and RLHF",
    "section": "Continued Pre-Training",
    "text": "Continued Pre-Training\n\ncontinued pre-training\nimage source: Sebastian Raschka",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#rl",
    "href": "slides/21_reward-models-and-rlhf.html#rl",
    "title": "21. Reward Models and RLHF",
    "section": "RL",
    "text": "RL\n\nreinforcement learning\nimage source: Hugging Face",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#preference-classification",
    "href": "slides/21_reward-models-and-rlhf.html#preference-classification",
    "title": "21. Reward Models and RLHF",
    "section": "Preference Classification",
    "text": "Preference Classification\n\npreference classification\nimage source: Sebastian Raschka",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#loss-function",
    "href": "slides/21_reward-models-and-rlhf.html#loss-function",
    "title": "21. Reward Models and RLHF",
    "section": "Loss Function",
    "text": "Loss Function\n\n\\(s_{w} = r_{\\theta}(x, y_{w})\\): reward for winning response\n\\(s_{\\ell} = r_{\\theta}(x, y_{\\ell})\\): reward for losing response\nGoal: minimize expected loss\n\n\\[-\\text{E}_{x}\\text{log}(\\sigma(s_{w} - s_{\\ell}))\\]\nThat is, reward model should not have \\(s_{w} &lt;&lt; s_{\\ell}\\)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#rlhf-1",
    "href": "slides/21_reward-models-and-rlhf.html#rlhf-1",
    "title": "21. Reward Models and RLHF",
    "section": "RLHF",
    "text": "RLHF\n\nRLHF workflow\nimage source: Hugging Face\n\n\n\nnote use of KL divergence",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#toward-dpo",
    "href": "slides/21_reward-models-and-rlhf.html#toward-dpo",
    "title": "21. Reward Models and RLHF",
    "section": "Toward DPO",
    "text": "Toward DPO\n\ntoward DPO\nimage source: Sebastian Raschka",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#human-feedback-moderation",
    "href": "slides/21_reward-models-and-rlhf.html#human-feedback-moderation",
    "title": "21. Reward Models and RLHF",
    "section": "Human Feedback (moderation)",
    "text": "Human Feedback (moderation)\n\nhuman feedback for moderation\nimage source: Chip Huyen by Chip Huyen (author)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#quality-of-model-outputs",
    "href": "slides/21_reward-models-and-rlhf.html#quality-of-model-outputs",
    "title": "21. Reward Models and RLHF",
    "section": "Quality of Model Outputs",
    "text": "Quality of Model Outputs\n\nBai et al., 2022",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/21_reward-models-and-rlhf.html#selling-points",
    "href": "slides/21_reward-models-and-rlhf.html#selling-points",
    "title": "21. Reward Models and RLHF",
    "section": "Selling Points",
    "text": "Selling Points\n\n\n\nSchulman, 2023",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "21. Reward Models and RLHF"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#why-distributed-training",
    "href": "slides/16_distributed-training-and-fsdp.html#why-distributed-training",
    "title": "16. Distributed Training and FSDP",
    "section": "Why Distributed Training?",
    "text": "Why Distributed Training?\nThe Scale Challenge: - Modern LLMs: 7B to 1T+ parameters - Single GPU memory (A100): Only 40-80GB - 7B model memory requirements: - Weights: ~14GB (FP16) - Gradients: ~14GB - Optimizer states: ~28GB (Adam) - Activations: Variable with batch size\nSolution: Split computation across multiple devices",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#hardware-requirements-for-llm-training",
    "href": "slides/16_distributed-training-and-fsdp.html#hardware-requirements-for-llm-training",
    "title": "16. Distributed Training and FSDP",
    "section": "Hardware Requirements for LLM Training",
    "text": "Hardware Requirements for LLM Training",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#gpu-memory-requirements",
    "href": "slides/16_distributed-training-and-fsdp.html#gpu-memory-requirements",
    "title": "16. Distributed Training and FSDP",
    "section": "GPU Memory Requirements",
    "text": "GPU Memory Requirements",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#parallelism-strategies",
    "href": "slides/16_distributed-training-and-fsdp.html#parallelism-strategies",
    "title": "16. Distributed Training and FSDP",
    "section": "Parallelism Strategies",
    "text": "Parallelism Strategies\nFour primary approaches:\n\nData Parallelism:\n\nSame model, different data batches\nSimple but limited by model size\n\nModel Parallelism:\n\nDifferent layers on different devices\nEnables larger models but sequential processing\n\nPipeline Parallelism:\n\nStages of model on different devices\nMultiple batches in pipeline\n\nTensor Parallelism:\n\nSplit individual operations (matrices)\nEfficient for Transformer operations\n\n\nImproving Optimization Performance with Parallelism Computing",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#full-sharded-data-parallelism-fsdp",
    "href": "slides/16_distributed-training-and-fsdp.html#full-sharded-data-parallelism-fsdp",
    "title": "16. Distributed Training and FSDP",
    "section": "Full Sharded Data Parallelism (FSDP)",
    "text": "Full Sharded Data Parallelism (FSDP)\nCore Concept: Shard model parameters, gradients, and optimizer states\nHow it works: - Each device stores only a portion of the full model - During forward/backward pass: - Gather needed parameters (all-gather) - Compute with gathered parameters - Re-shard parameters after use\nBenefits: - ~N-fold memory reduction with N devices - Enables training much larger models - Preserves computation efficiency of data parallelism",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#full-sharded-data-parallelism-fsdp-1",
    "href": "slides/16_distributed-training-and-fsdp.html#full-sharded-data-parallelism-fsdp-1",
    "title": "16. Distributed Training and FSDP",
    "section": "Full Sharded Data Parallelism (FSDP)",
    "text": "Full Sharded Data Parallelism (FSDP)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#critical-memory-optimizations",
    "href": "slides/16_distributed-training-and-fsdp.html#critical-memory-optimizations",
    "title": "16. Distributed Training and FSDP",
    "section": "Critical Memory Optimizations",
    "text": "Critical Memory Optimizations\nCombine these techniques for maximum efficiency:\n\nMixed Precision Training:\n\nUse BF16/FP16 for most operations\nMaintain FP32 master weights for stability\n2x memory reduction\n\nActivation Checkpointing:\n\nDiscard activations during forward pass\nRecompute during backward pass\nTrade computation for memory\n\nGradient Accumulation:\n\nUpdate less frequently\nProcess more data with same memory",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#fsdp-implementation-pytorch",
    "href": "slides/16_distributed-training-and-fsdp.html#fsdp-implementation-pytorch",
    "title": "16. Distributed Training and FSDP",
    "section": "FSDP Implementation (PyTorch)",
    "text": "FSDP Implementation (PyTorch)\nBasic implementation:\n# Initialize distributed process group\ntorch.distributed.init_process_group(\"nccl\")\n\n# Wrap model with FSDP\nmodel = FSDP(\n    model,\n    sharding_strategy=ShardingStrategy.FULL_SHARD,\n    mixed_precision=mp_policy,\n    device_id=torch.cuda.current_device()\n)\n\n# Train normally\nfor batch in dataloader:\n    loss = model(batch).loss\n    loss.backward()\n    optimizer.step()",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#hardware-communication-considerations",
    "href": "slides/16_distributed-training-and-fsdp.html#hardware-communication-considerations",
    "title": "16. Distributed Training and FSDP",
    "section": "Hardware & Communication Considerations",
    "text": "Hardware & Communication Considerations\nHardware Topology: - Intra-node: High-speed GPU connections (NVLink) - Inter-node: Network connections (InfiniBand)\nCommunication Bottlenecks: - All-gather: Collect sharded parameters - Reduce-scatter: Aggregate gradients - Communication volume grows with model size\nOptimization Strategies: - Match parallelism strategy to hardware topology - Hierarchical communication patterns - Overlap computation with communication",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#d-parallelism-state-of-the-art",
    "href": "slides/16_distributed-training-and-fsdp.html#d-parallelism-state-of-the-art",
    "title": "16. Distributed Training and FSDP",
    "section": "3D Parallelism: State-of-the-Art",
    "text": "3D Parallelism: State-of-the-Art\nCombining complementary strategies:\n\nData Parallelism/FSDP: Across node groups\nPipeline Parallelism: Between GPU clusters\nTensor Parallelism: Within GPU clusters\n\nExample (175B model training): - 8-way tensor parallelism - 12-way pipeline parallelism - 32-way data parallelism - Total: 3,072 GPUs\nUsed by major labs for largest models",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#d-parallelism",
    "href": "slides/16_distributed-training-and-fsdp.html#d-parallelism",
    "title": "16. Distributed Training and FSDP",
    "section": "3D Parallelism",
    "text": "3D Parallelism",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#practical-training-challenges",
    "href": "slides/16_distributed-training-and-fsdp.html#practical-training-challenges",
    "title": "16. Distributed Training and FSDP",
    "section": "Practical Training Challenges",
    "text": "Practical Training Challenges\n\nCheckpoint Management:\n\nTB-sized checkpoints\nDistributed saving/loading\n\nFault Tolerance:\n\nHardware failures increasingly likely at scale\nNeed robust recovery mechanisms\n\nPerformance Debugging:\n\nComplex interactions between strategies\nProfiling distributed workloads\n\nCost Management:\n\nTraining budgets in millions of dollars\nEfficiency optimizations have major impact",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#frameworks-and-resources",
    "href": "slides/16_distributed-training-and-fsdp.html#frameworks-and-resources",
    "title": "16. Distributed Training and FSDP",
    "section": "Frameworks and Resources",
    "text": "Frameworks and Resources\nPopular Frameworks:\n\n- PyTorch FSDP: Native PyTorch implementation\n- DeepSpeed: Microsoft’s ZeRO implementation\n- Megatron-LM: NVIDIA’s specialized framework\n- JAX/Flax: Google’s functional approach\n\nLearning Resources:\n\n- PyTorch FSDP Tutorial\n- DeepSpeed ZeRO Paper\n- Megatron-LM GitHub",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/16_distributed-training-and-fsdp.html#key-takeaways",
    "href": "slides/16_distributed-training-and-fsdp.html#key-takeaways",
    "title": "16. Distributed Training and FSDP",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nDistributed training essential for modern LLMs\nFSDP provides memory-efficient data parallelism\nCombine multiple parallelism strategies for best results\nMemory optimizations as important as compute scaling\nHardware topology should inform parallelism strategy\nLLM training represents extreme engineering challenge",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "16. Distributed Training and FSDP"
    ]
  },
  {
    "objectID": "slides/31_llms-for-synthetic-data.html#slide",
    "href": "slides/31_llms-for-synthetic-data.html#slide",
    "title": "31. LLMs for Synthetic Data",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "31. LLMs for Synthetic Data"
    ]
  },
  {
    "objectID": "slides/31_llms-for-synthetic-data.html#slide-1",
    "href": "slides/31_llms-for-synthetic-data.html#slide-1",
    "title": "31. LLMs for Synthetic Data",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "31. LLMs for Synthetic Data"
    ]
  },
  {
    "objectID": "slides/31_llms-for-synthetic-data.html#slide-2",
    "href": "slides/31_llms-for-synthetic-data.html#slide-2",
    "title": "31. LLMs for Synthetic Data",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "31. LLMs for Synthetic Data"
    ]
  },
  {
    "objectID": "slides/31_llms-for-synthetic-data.html#slide-3",
    "href": "slides/31_llms-for-synthetic-data.html#slide-3",
    "title": "31. LLMs for Synthetic Data",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "31. LLMs for Synthetic Data"
    ]
  },
  {
    "objectID": "slides/28_vector-databases-and-reranking.html#vector-databases-1",
    "href": "slides/28_vector-databases-and-reranking.html#vector-databases-1",
    "title": "28. Vector Databases and Reranking",
    "section": "Vector databases",
    "text": "Vector databases\nVector databases facilitate semantic search on your data.\n\nEmbedding models return vectors and LLM understand context from those vectors.\nUsed for Retrieval-Augmented Generation systems to query documents.\n\n\nVector database\nImage from What is a Vector Database & How Does it Work?",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "28. Vector Databases and Reranking"
    ]
  },
  {
    "objectID": "slides/28_vector-databases-and-reranking.html#indexes-and-distances",
    "href": "slides/28_vector-databases-and-reranking.html#indexes-and-distances",
    "title": "28. Vector Databases and Reranking",
    "section": "Indexes and distances",
    "text": "Indexes and distances\n\n\nDistance (far) or similarity (close):\n\nEuclidean distance\nCosine similarity\nHamming\nManhattan\n\n\nIndexing algorithms:\n\nExact nearest neighbor: linear search, k-nearest neighbors, space partitioning.\nApproximate nearest neighbor:\n\nIVFFFlat Inverted file with flat compression.\nLocality-sensitive hashing (LSH)\nApproximate Nearest Neighbors Oh yeah (ANNOY)\nHierarchical Navigable Small World (HNSW)",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "28. Vector Databases and Reranking"
    ]
  },
  {
    "objectID": "slides/28_vector-databases-and-reranking.html#some-popular-vector-databases",
    "href": "slides/28_vector-databases-and-reranking.html#some-popular-vector-databases",
    "title": "28. Vector Databases and Reranking",
    "section": "Some popular vector databases",
    "text": "Some popular vector databases\n\nVector databases\nImage from What are Vector Databases? A Beginner’s Guide?",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "28. Vector Databases and Reranking"
    ]
  },
  {
    "objectID": "slides/28_vector-databases-and-reranking.html#section",
    "href": "slides/28_vector-databases-and-reranking.html#section",
    "title": "28. Vector Databases and Reranking",
    "section": "",
    "text": "Retrieval Augmented Generation (RAG) is more than putting documents into a vector DB and adding an LLM on top.\n\n\nRecall: how many of the relevant documents are we retrieving.\nLLM recall : the ability of an LLM to find information from the text placed within its context window (its RAM).\n\nMore tokens in the context window, less LLM recall.\n\n\n\n\nRecall and context window\n\nWe cannot return everything because of context window.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "28. Vector Databases and Reranking"
    ]
  },
  {
    "objectID": "slides/28_vector-databases-and-reranking.html#section-1",
    "href": "slides/28_vector-databases-and-reranking.html#section-1",
    "title": "28. Vector Databases and Reranking",
    "section": "",
    "text": "Maximize retrieval recall by retrieving plenty of documents and then maximize LLM recall by minimizing the number of documents that make it to the LLM\n\nSolution: Reranker model\n\nReranker",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "28. Vector Databases and Reranking"
    ]
  },
  {
    "objectID": "slides/28_vector-databases-and-reranking.html#reranker-model",
    "href": "slides/28_vector-databases-and-reranking.html#reranker-model",
    "title": "28. Vector Databases and Reranking",
    "section": "Reranker model",
    "text": "Reranker model\nGiven a query and document pair, the reranker reorders the documents by relevance to our query using a similarity score.\nTwo stages:\n\nEmbedding model/retriever: Fast.\n\nRetrieves a set of relevant documents from a larger datase\n\nReranker: Slow.\n\nReranks the documents retrieved by the first-stage model.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "28. Vector Databases and Reranking"
    ]
  },
  {
    "objectID": "slides/39_cpu-offloading.html#slide",
    "href": "slides/39_cpu-offloading.html#slide",
    "title": "39. CPU Offloading",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "39. CPU Offloading"
    ]
  },
  {
    "objectID": "slides/39_cpu-offloading.html#slide-1",
    "href": "slides/39_cpu-offloading.html#slide-1",
    "title": "39. CPU Offloading",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "39. CPU Offloading"
    ]
  },
  {
    "objectID": "slides/39_cpu-offloading.html#slide-2",
    "href": "slides/39_cpu-offloading.html#slide-2",
    "title": "39. CPU Offloading",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "39. CPU Offloading"
    ]
  },
  {
    "objectID": "slides/39_cpu-offloading.html#slide-3",
    "href": "slides/39_cpu-offloading.html#slide-3",
    "title": "39. CPU Offloading",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "39. CPU Offloading"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#why-positional-encoding",
    "href": "slides/14_positional-encoding.html#why-positional-encoding",
    "title": "14. Positional Encoding",
    "section": "Why Positional Encoding?",
    "text": "Why Positional Encoding?\n\nTransformers lack recurrence (unlike RNNs)\nNo inherent sense of word order\nSolution: Add positional info to token embeddings",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#the-power-of-positional-encoding",
    "href": "slides/14_positional-encoding.html#the-power-of-positional-encoding",
    "title": "14. Positional Encoding",
    "section": "The Power of Positional Encoding",
    "text": "The Power of Positional Encoding",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#transformer-architecture",
    "href": "slides/14_positional-encoding.html#transformer-architecture",
    "title": "14. Positional Encoding",
    "section": "Transformer Architecture",
    "text": "Transformer Architecture",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#naive-approaches",
    "href": "slides/14_positional-encoding.html#naive-approaches",
    "title": "14. Positional Encoding",
    "section": "Naive Approaches",
    "text": "Naive Approaches\n\nOne-hot encoding: Unique vector per position\n\nIssue: Doesn’t scale, no ordinality\n\nLinear indices: 1, 2, 3, …\n\nIssue: Large values, poor generalization\n\nNeed: Unique, bounded, relative-aware encoding",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#sinusoidal-positional-encoding",
    "href": "slides/14_positional-encoding.html#sinusoidal-positional-encoding",
    "title": "14. Positional Encoding",
    "section": "Sinusoidal Positional Encoding",
    "text": "Sinusoidal Positional Encoding\n\nProposed in “Attention is All You Need” Vaswani et al.\nFor position ( k ), dimension ( d ):\n\n( P(k, 2i) = (k / 10000^{2i/d}) )\n( P(k, 2i+1) = (k / 10000^{2i/d}) )\n\nVector per position, added to token embedding",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#how-it-works",
    "href": "slides/14_positional-encoding.html#how-it-works",
    "title": "14. Positional Encoding",
    "section": "How It Works",
    "text": "How It Works\n\nSine/cosine pairs at varying frequencies\nWavelengths: ( 2) to ( 2 )\nProperties:\n\nUnique per position\nConsistent distances\nGeneralizes to longer sequences",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#visualization",
    "href": "slides/14_positional-encoding.html#visualization",
    "title": "14. Positional Encoding",
    "section": "Visualization",
    "text": "Visualization\n\nImagine a 512-dim encoding for 100-token sequence\nSee Mehreen Saeed’s blog for a plot\nEach row = position, each column = dimension\nGradual frequency shift encodes order",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/14_positional-encoding.html#modern-twist-rope",
    "href": "slides/14_positional-encoding.html#modern-twist-rope",
    "title": "14. Positional Encoding",
    "section": "Modern Twist: RoPE",
    "text": "Modern Twist: RoPE\n\nRotary Positional Encoding (RoPE):\n\nRotates embeddings based on position\nMore stable, faster to learn\n\nWidely used in frontier LLMs (e.g., LLaMA)\nCheck Eleuther AI’s blog for details",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "14. Positional Encoding"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#learning-objectives",
    "href": "slides/24_distillation-and-merging.html#learning-objectives",
    "title": "24. Distillation and Merging",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nFinish module on fine tuning\nLearn to train a “student” with a “teacher”\n\n\n\nIt would be nice to have a simple tutorial here",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#sources",
    "href": "slides/24_distillation-and-merging.html#sources",
    "title": "24. Distillation and Merging",
    "section": "Sources",
    "text": "Sources\nFollowing the Gen AI Handbook, we looked at\n\nblog post by Victor Sanh (Hugging Face)\nblog post by Matt Casey (Snorkel AI)\nblog post by Cheng-Yu Hsieh, et al. (Google Research)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#temperature",
    "href": "slides/24_distillation-and-merging.html#temperature",
    "title": "24. Distillation and Merging",
    "section": "Temperature",
    "text": "Temperature\nAnother hyperparameter is the softmax temperature\n\\[p_{i} = \\frac{exp(z_{i}/T)}{\\sum_{j} exp(z_{j}/T)}\\]\n\n\\(T \\rightarrow 0\\): one-hot target vector\n\\(T \\rightarrow \\infty\\): uniform distribution (random guessing)",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#kl-loss",
    "href": "slides/24_distillation-and-merging.html#kl-loss",
    "title": "24. Distillation and Merging",
    "section": "KL Loss",
    "text": "KL Loss\nKullback-Leibler loss is defined as\n\\[\\begin{array}{rcl}\nKL(p||q) & = & \\text{E}_{p}[\\log \\frac{p}{q}] \\\\\n~ & = & \\displaystyle\\sum_{i} p_{i} \\cdot \\log(p_{i}) - \\sum_{i} p_{i} \\cdot \\log(q_{i})\n\\end{array}\\]",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#transformers",
    "href": "slides/24_distillation-and-merging.html#transformers",
    "title": "24. Distillation and Merging",
    "section": "Transformers",
    "text": "Transformers\n\nEncoder-only: BERT\n\n\nbidirectional encoder representations from transformers\n\n\nDecoder-only: GPT\n\n\ngenerative pre-trained transformer",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#encoders-vs-decoders",
    "href": "slides/24_distillation-and-merging.html#encoders-vs-decoders",
    "title": "24. Distillation and Merging",
    "section": "Encoders vs Decoders",
    "text": "Encoders vs Decoders\n\nBERT vs GPT\nimage source: Ronak Verma",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#applications",
    "href": "slides/24_distillation-and-merging.html#applications",
    "title": "24. Distillation and Merging",
    "section": "Applications",
    "text": "Applications\n\nBERT\n\ntext classification\ndata labeling\nrecommender\nsentiment analysis\n\nGPT\n\ncontent generation\nconversational chatbots",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#fine-tuning",
    "href": "slides/24_distillation-and-merging.html#fine-tuning",
    "title": "24. Distillation and Merging",
    "section": "Fine Tuning",
    "text": "Fine Tuning\n\ndistillation motivation\nimage source: Google Research",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#teacher-and-student",
    "href": "slides/24_distillation-and-merging.html#teacher-and-student",
    "title": "24. Distillation and Merging",
    "section": "Teacher and Student",
    "text": "Teacher and Student\n\nteacher and student\nResearchers at the University of California at Berkeley found a way to change this, which they call “context distillation.” They built heavily-engineered prompts that ended with simple questions, such as “add these numbers.” Then, they stripped the prompt of its engineering and reduced the response to only its final answer to create a new data set that they used to fine-tune the model.\n\n\nimage source: Snorkel AI",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#chain-of-thought",
    "href": "slides/24_distillation-and-merging.html#chain-of-thought",
    "title": "24. Distillation and Merging",
    "section": "Chain of Thought",
    "text": "Chain of Thought\n\nchain of thought\nimage source: Snorkel AI",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/24_distillation-and-merging.html#distilbert-performance",
    "href": "slides/24_distillation-and-merging.html#distilbert-performance",
    "title": "24. Distillation and Merging",
    "section": "DistilBERT Performance",
    "text": "DistilBERT Performance\n\n\n\nDistilBERT performance",
    "crumbs": [
      "Section IV: Finetuning Methods for LLMs",
      "24. Distillation and Merging"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#anns",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#anns",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "ANNs",
    "text": "ANNs\n\nAn Artificial Neural Network (ANN) is machine learning model designed to find nonlinear patterns in data.\nIt is a set of connected units aggregated into layers.\nEach neuron receives signals (real numbers) from its connected neurons and process its inputs through an activation function.\nANNs are trained to minimize the difference between the predicted output and the actual target values in a given dataset.\nTraining requires adjusting function parameters\nNeural Networks and Deep Learning - Chapter 1",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#network-architecture",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#network-architecture",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Network architecture",
    "text": "Network architecture\n\nThe number of neurons in the input/output layers is related to their application.\n\n\n\n1 neuron input with 1 neuron output: Ex. drug dosage and binary response. Like linear regression\nN neuron inputs, M neuron outputs: N number of features. M number of categories in classification.\n* Example: classification of images into digits. 28x28 input neuron from a 28x28px image and 10 output networks for digits.\n\n\n\n\n\nNeural Net for 28x28 image",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#the-perceptron",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#the-perceptron",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "The Perceptron",
    "text": "The Perceptron\n\n\nA type of artificial neuron developed in the 1950s and the 1960s\n\n\n\n\n\n\nPerceptron\n\n\n\nIt takes several binary inputs \\(x_1,x_2,x_3\\) and produces a single binary output\nEach input has an associated weight \\(w_1,w_2,w_3\\) indicating the importance of its input to the output.\n\nTo calculate the output: \\[ output = \\left\\{\n\\begin{array}{ll}\n      0 & \\text{if } \\sum_jw_jx_j \\leq \\text{threshold}\\\\\n      1 & \\text{if } \\sum_jw_jx_j \\geq \\text{threshold} \\\\\n\\end{array}\n\\right.  \\]\nA network of perceptrons could weigh up evidence and make decisions, like computing logical functions with binary operations such as AND, OR or NAND gates.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#from-binary-to-sigmoid-functions",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#from-binary-to-sigmoid-functions",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "From binary to sigmoid functions",
    "text": "From binary to sigmoid functions\n\n\n\n\n\n\nSigmoid neuron. Same structure as perceptron\n\n\n\n\n\n\nSigmoid function\n\n\n\nThe output is defined by the sigmoid function:\n\n\n\\[\\sigma(z)=\\frac{1}{1+e^{-z}}\\] \\[\\sigma(w\\cdot x+b)=\\frac{1}{1+exp(-\\sum_jw_jx_j-b)}\\]\n\nInputs \\(x_j\\) and single output in the \\([0,1]\\) range.\nWeights, \\(w_j\\) tell us how important each input is.\nBias \\(b\\) tell us how high the sum needs to be to activate the neuron.\n\nOther activation functions: ReLU, Softax, etc",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#section",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#section",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "",
    "text": "ANN learningFrom: But what is a neural network? | Deep learning chapter 1",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#section-1",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#section-1",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "",
    "text": "From: But what is a neural network? | Deep learning chapter 1 Matrix operations\n\nwe’re thinking of each neuron as being connected to all the neurons in the previous layer, and the weights in the weighted sum defining its activation are kind of like the strengths of those connections, and the bias is some indication of whether that neuron tends to be active or inactive.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#cost-function",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#cost-function",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Cost function",
    "text": "Cost function\nGoal: find weights and biases so that the output of the network approximates \\(f(x)\\) for all training inputs.\nTo evaluate how well we’re achieving this goal, we define a cost function, also referred to as loss or objective function.\nCommon one: mean squared error\n\\[\nC(w,b) = \\frac{1}{2n}\\sum_x ||y(x)-a||^2\n\\] We want \\(C(w,b)\\approx 0\\), so we want to minimize the function",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#gradient-descent",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#gradient-descent",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Gradient descent",
    "text": "Gradient descent\nIn \\(x,y\\), the slope of the derivative is the rate of change of a function at a specific point.\n\nFrom: Gradient descent, how neural networks learn | DL2",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#gradient-descend",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#gradient-descend",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Gradient descend",
    "text": "Gradient descend",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#gradient-descend-calculation",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#gradient-descend-calculation",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Gradient descend calculation",
    "text": "Gradient descend calculation\nWith partial derivatives using the chain rule (from Leibniz)\nA very simple example:",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#algorithm",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#algorithm",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Algorithm",
    "text": "Algorithm\n\n\n\nInputs are propagated from the input to the output layer.\nThe network error is calculated.\nThe error is propagated from the output layer to the input layer - backpropagation.\n\n\n\n\n\nForward-Backward\n\n\n\nWe get the derivatives of the cost function with respect to each individual \\(w\\) and \\(b\\) and update them according to a learning rate.\nWe repeat until the change is really small or we reach some other condition.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#again",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#again",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Again",
    "text": "Again\n\nTraining AlgorithmFrom: How the backpropagation algorithm works",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#backpropagation-implementation",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#backpropagation-implementation",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Backpropagation implementation",
    "text": "Backpropagation implementation\n\nHacker’s guide to Neural Networks by Andrej Karpathy\nA Comprehensive Guide to the Backpropagation Algorithm in Neural Networks by neptune.ai\nHow the backpropagation algorithm works by Michael Nielsen",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/07_statistical-prediction-with-neural-networks.html#artificial-neural-networks",
    "href": "slides/07_statistical-prediction-with-neural-networks.html#artificial-neural-networks",
    "title": "7. Statistical Prediction with Neural Networks",
    "section": "Artificial Neural Networks",
    "text": "Artificial Neural Networks\nWhat do we need?\n\nA network structure with input, output and h hidden layers.\nOne weight value per link (neuron-neuron connection).\nOne bias value per neuron.\nAn activation function for the neurons, usually ReLU or sigmoid.\nA cost function to minimize during training and to tune weight and biases values.\nA training algorithm more like stochastic gradient descent.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "7. Statistical Prediction with Neural Networks"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#definition",
    "href": "slides/47_generative-adversarial-nets.html#definition",
    "title": "47. Generative Adversarial Nets",
    "section": "Definition",
    "text": "Definition\n\n“Generative AI is a form of artificial intelligence that is designed to generate content, including text, images, video and music. It uses large language models and algorithms to analyze patterns in datasets to mimic the style or structure of specific types of content.”\n\n\ngenerative AI\nquote and image source",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#dall-e",
    "href": "slides/47_generative-adversarial-nets.html#dall-e",
    "title": "47. Generative Adversarial Nets",
    "section": "Dall-E",
    "text": "Dall-E\n\nJune 2022image source",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#stable-diffusion",
    "href": "slides/47_generative-adversarial-nets.html#stable-diffusion",
    "title": "47. Generative Adversarial Nets",
    "section": "Stable Diffusion",
    "text": "Stable Diffusion\n\nAugust 2023image source",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#overview",
    "href": "slides/47_generative-adversarial-nets.html#overview",
    "title": "47. Generative Adversarial Nets",
    "section": "Overview",
    "text": "Overview\n\nGANs overview\nimage source: Deep Learning Illustrated",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#discriminator",
    "href": "slides/47_generative-adversarial-nets.html#discriminator",
    "title": "47. Generative Adversarial Nets",
    "section": "Discriminator",
    "text": "Discriminator\n\nTraining the discriminator\nimage source: Deep Learning Illustrated",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#generator",
    "href": "slides/47_generative-adversarial-nets.html#generator",
    "title": "47. Generative Adversarial Nets",
    "section": "Generator",
    "text": "Generator\n\nTraining the generator\nimage source: Deep Learning Illustrated",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#gan-objectives",
    "href": "slides/47_generative-adversarial-nets.html#gan-objectives",
    "title": "47. Generative Adversarial Nets",
    "section": "GAN Objectives",
    "text": "GAN Objectives\n\nthe goal of a generator is to create better fake images\nthe goal of a discriminator is to better classify fake images",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#adversarial-network",
    "href": "slides/47_generative-adversarial-nets.html#adversarial-network",
    "title": "47. Generative Adversarial Nets",
    "section": "Adversarial Network",
    "text": "Adversarial Network\n\nAdversarial network\nimage source: Deep Learning Illustrated",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/47_generative-adversarial-nets.html#initial-results",
    "href": "slides/47_generative-adversarial-nets.html#initial-results",
    "title": "47. Generative Adversarial Nets",
    "section": "Initial Results",
    "text": "Initial Results\n\n\n\nGoodfellow, et al., 2014",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "47. Generative Adversarial Nets"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#cgans",
    "href": "slides/48_conditional-gans.html#cgans",
    "title": "48. Conditional GANs",
    "section": "cGANs",
    "text": "cGANs\n“We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations.”\n\nIsola, et al.",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#example",
    "href": "slides/48_conditional-gans.html#example",
    "title": "48. Conditional GANs",
    "section": "example",
    "text": "example\n\ncGAN in ecology\nimage source: Hayatbini, et al.",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#activity-pix2pix-image-to-image",
    "href": "slides/48_conditional-gans.html#activity-pix2pix-image-to-image",
    "title": "48. Conditional GANs",
    "section": "Activity: Pix2Pix Image-to-Image",
    "text": "Activity: Pix2Pix Image-to-Image\n\nimage-to-image\napp (link) by Christopher Hesse\nGitHub repo",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#activity-pix2pix-instruct",
    "href": "slides/48_conditional-gans.html#activity-pix2pix-instruct",
    "title": "48. Conditional GANs",
    "section": "Activity: Pix2Pix Instruct",
    "text": "Activity: Pix2Pix Instruct\n\npix2pix\napp (link) by Tim Brooks\nGitHub repo",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#stacked-gans-1",
    "href": "slides/48_conditional-gans.html#stacked-gans-1",
    "title": "48. Conditional GANs",
    "section": "Stacked GANs",
    "text": "Stacked GANs\n\n“Stage-I GAN sketches the primitive shape and colors of the object based on the given text description, yielding Stage-I low-resolution images”\n” Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details”\n\n\nZhang, et al., 2016",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#architecture",
    "href": "slides/48_conditional-gans.html#architecture",
    "title": "48. Conditional GANs",
    "section": "Architecture",
    "text": "Architecture\n\nZhang, et al., 2016",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#scaling",
    "href": "slides/48_conditional-gans.html#scaling",
    "title": "48. Conditional GANs",
    "section": "Scaling",
    "text": "Scaling\n\nZhang, et al., 2016",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#cgans-1",
    "href": "slides/48_conditional-gans.html#cgans-1",
    "title": "48. Conditional GANs",
    "section": "cGANs",
    "text": "cGANs\n\n“… learning to translate an image from a source domain \\(X\\) to a target domain \\(Y\\) in the absence of paired examples …” — Jun-Yan Zhu, et al., 2017\n\n\ncycle GAN possibilities",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#architecture-1",
    "href": "slides/48_conditional-gans.html#architecture-1",
    "title": "48. Conditional GANs",
    "section": "Architecture",
    "text": "Architecture",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/48_conditional-gans.html#cgan-objective",
    "href": "slides/48_conditional-gans.html#cgan-objective",
    "title": "48. Conditional GANs",
    "section": "cGAN Objective",
    "text": "cGAN Objective\nIn a cyclic GAN, the generator and discriminator converge toward a Nash equilibrium.\n\ncycle GAN architecture\nimages source: Bansal and Rathore",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "48. Conditional GANs"
    ]
  },
  {
    "objectID": "slides/02_statistical-prediction-and-supervised-learning.html#regression-vs-classification",
    "href": "slides/02_statistical-prediction-and-supervised-learning.html#regression-vs-classification",
    "title": "2. Statistical Prediction and Supervised Learning",
    "section": "Regression vs Classification",
    "text": "Regression vs Classification\n\nRegression or Classificationimage source: Sharp Sight Labs",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "2. Statistical Prediction and Supervised Learning"
    ]
  },
  {
    "objectID": "slides/02_statistical-prediction-and-supervised-learning.html#supervised-learning-vs-unsupervised-learning",
    "href": "slides/02_statistical-prediction-and-supervised-learning.html#supervised-learning-vs-unsupervised-learning",
    "title": "2. Statistical Prediction and Supervised Learning",
    "section": "Supervised Learning vs Unsupervised Learning",
    "text": "Supervised Learning vs Unsupervised Learning\n\nSupervised or Unsupervisedimage source: Ma Yan, et al",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "2. Statistical Prediction and Supervised Learning"
    ]
  },
  {
    "objectID": "slides/02_statistical-prediction-and-supervised-learning.html#regularization",
    "href": "slides/02_statistical-prediction-and-supervised-learning.html#regularization",
    "title": "2. Statistical Prediction and Supervised Learning",
    "section": "Regularization",
    "text": "Regularization\n\nLoss function \\[L(\\vec{\\beta}) = \\text{argmin}_{\\vec{\\beta}} \\sum_{i=1}^{N} \\left(y_{i} - \\beta_{0} - \\sum_{j=1}^{k} \\beta_{j}x_{ij}\\right)^{2}\\]\nL1 Regularization \\[L(\\vec{\\beta}, \\lambda) = \\text{argmin}_{\\vec{\\beta}} \\left[\\sum_{i=1}^{N} \\left(y_{i} - \\beta_{0} - \\sum_{j=1}^{k} \\beta_{j}x_{ij}\\right)^{2} + \\lambda\\sum_{j=i}^{k}|\\beta_{j}|\\right]\\]\nL2 Regularization \\[L(\\vec{\\beta}, \\lambda) = \\text{argmin}_{\\vec{\\beta}} \\left[\\sum_{i=1}^{N} \\left(y_{i} - \\beta_{0} - \\sum_{j=1}^{k} \\beta_{j}x_{ij}\\right)^{2} + \\lambda\\sum_{j=i}^{k}\\beta_{j}^{2}\\right]\\]",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "2. Statistical Prediction and Supervised Learning"
    ]
  },
  {
    "objectID": "slides/02_statistical-prediction-and-supervised-learning.html#empirical-risk-minimization",
    "href": "slides/02_statistical-prediction-and-supervised-learning.html#empirical-risk-minimization",
    "title": "2. Statistical Prediction and Supervised Learning",
    "section": "Empirical Risk Minimization",
    "text": "Empirical Risk Minimization\nWe can approximate the expected risk over a loss function, data set, and hypothesis model \\(h\\)\n\\[\\text{E}\\left[L((\\vec{x}, \\vec{y}), h)\\right]\\] by taking the average over the training data\n\\[\\frac{1}{n}\\displaystyle\\sum_{i=1}^{n} L((x_{i}, y_{i}), h)\\] * formulas outlined by Professor Alexander Jung",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "2. Statistical Prediction and Supervised Learning"
    ]
  },
  {
    "objectID": "slides/02_statistical-prediction-and-supervised-learning.html#bias-variance-tradeoff",
    "href": "slides/02_statistical-prediction-and-supervised-learning.html#bias-variance-tradeoff",
    "title": "2. Statistical Prediction and Supervised Learning",
    "section": "Bias-Variance Tradeoff",
    "text": "Bias-Variance Tradeoff\nWithin a hypothesis class of similar modeling functions, we are concerned with the bias-variance tradeoff in model selection.\n\nbias-variance tradeoffimage source: Scott Fortmann-Roe",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "2. Statistical Prediction and Supervised Learning"
    ]
  },
  {
    "objectID": "slides/02_statistical-prediction-and-supervised-learning.html#linear-foundations",
    "href": "slides/02_statistical-prediction-and-supervised-learning.html#linear-foundations",
    "title": "2. Statistical Prediction and Supervised Learning",
    "section": "Linear Foundations",
    "text": "Linear Foundations\n“For more complex and high-dimensional problems with potential nonlinear dependencies between features, it’s often useful to ask:\n\nWhat’s a linear model for the problem?\nWhy does the linear model fail?\nWhat’s the best way to add nonlinearity, given the semantic structure of the problem?",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "2. Statistical Prediction and Supervised Learning"
    ]
  },
  {
    "objectID": "slides/12_decoder-only-transformers.html#slide",
    "href": "slides/12_decoder-only-transformers.html#slide",
    "title": "12. Decoder-Only Transformers",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "12. Decoder-Only Transformers"
    ]
  },
  {
    "objectID": "slides/12_decoder-only-transformers.html#slide-1",
    "href": "slides/12_decoder-only-transformers.html#slide-1",
    "title": "12. Decoder-Only Transformers",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "12. Decoder-Only Transformers"
    ]
  },
  {
    "objectID": "slides/12_decoder-only-transformers.html#slide-2",
    "href": "slides/12_decoder-only-transformers.html#slide-2",
    "title": "12. Decoder-Only Transformers",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "12. Decoder-Only Transformers"
    ]
  },
  {
    "objectID": "slides/12_decoder-only-transformers.html#slide-3",
    "href": "slides/12_decoder-only-transformers.html#slide-3",
    "title": "12. Decoder-Only Transformers",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "12. Decoder-Only Transformers"
    ]
  },
  {
    "objectID": "slides/01_preliminaries.html#ai-landscape",
    "href": "slides/01_preliminaries.html#ai-landscape",
    "title": "1. Preliminaries",
    "section": "AI Landscape",
    "text": "AI Landscape\n\nareas for artificial intelligenceimage source: RapidOps",
    "crumbs": [
      "Introduction",
      "1. Preliminaries"
    ]
  },
  {
    "objectID": "slides/01_preliminaries.html#math-topics",
    "href": "slides/01_preliminaries.html#math-topics",
    "title": "1. Preliminaries",
    "section": "Math Topics",
    "text": "Math Topics\n\n\nGradients and their relation to local minima/maxima\nThe chain rule for differentiation\nMatrices as linear transformations for vectors\nNotions of basis/rank/span/independence/etc.\n\n\n\ncalculus\nlinear algebra",
    "crumbs": [
      "Introduction",
      "1. Preliminaries"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#why-is-sampling-important",
    "href": "slides/26_sampling-and-structured-outputs.html#why-is-sampling-important",
    "title": "26. Sampling and Structured Outputs",
    "section": "Why is sampling important?",
    "text": "Why is sampling important?\nLLMs don’t directly produce text.\nThey calculate logits: scores assigned to every possible token.\n\nLogits in LLMSHow do these probabilities generate text? With decoding methods",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#greedy-search",
    "href": "slides/26_sampling-and-structured-outputs.html#greedy-search",
    "title": "26. Sampling and Structured Outputs",
    "section": "Greedy search",
    "text": "Greedy search\nIt takes the most probable token at each step as the next token in the sequence.\nIt discard all other potential options.\nIt can miss out on better overall sequences.\n\nIt sounds intuitive but it is short-sighted: it doesn’t consider the overall effect on the sequence. It can miss out on better sequences that might have appeared with slightly less probable next tokens.\n\n\n\n\nStep 1: Input: I have a dream → ” of”\nStep 2: Input: I have a dream of → ” being”\nStep 3: Input: I have a dream of being → ” a”\nStep 4: Input: I have a dream of being a → ” doctor”\nStep 5: Input: I have a dream of being a doctor → “.”\n\nGenerated text: I have a dream of being a doctor.\n\n\n\n\nGreedy decoding",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#beam-search",
    "href": "slides/26_sampling-and-structured-outputs.html#beam-search",
    "title": "26. Sampling and Structured Outputs",
    "section": "Beam search",
    "text": "Beam search\nIt takes the n most likely tokens (number of beams)\nIt repeats until max length or end-of-sequence token\n\nBeam decodingIt chooses the beam or sequence with the highest overall score.\nGenerated text: I have a dream. I have a dream",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#top-k-sampling",
    "href": "slides/26_sampling-and-structured-outputs.html#top-k-sampling",
    "title": "26. Sampling and Structured Outputs",
    "section": "Top-k sampling",
    "text": "Top-k sampling\nIt uses the probability distribution to select a token from the k most likely options.\nIt introduces randomness in the selection process.\n\nTop-k distributionIt can use the temperature parameter\n\nTemperature alters the probability distribution (1.0 is no temperature). It controls the level of creativity.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#top-k-sampling-1",
    "href": "slides/26_sampling-and-structured-outputs.html#top-k-sampling-1",
    "title": "26. Sampling and Structured Outputs",
    "section": "Top-k sampling",
    "text": "Top-k sampling\n\nTop-kGenerated text: I have a dream job and I want to",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#nucleus-sampling-or-top-p-sampling",
    "href": "slides/26_sampling-and-structured-outputs.html#nucleus-sampling-or-top-p-sampling",
    "title": "26. Sampling and Structured Outputs",
    "section": "Nucleus sampling or Top-p sampling",
    "text": "Nucleus sampling or Top-p sampling\nIt chooses a cutoff value p such as the sum of the probabilities of the selected tokens exceeds p.\nIt forms a nucleus of tokens from which to randomly choose the next token.\n\nTop-p distributionThe number of tokens on the nucleus can vary from step to step.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#section",
    "href": "slides/26_sampling-and-structured-outputs.html#section",
    "title": "26. Sampling and Structured Outputs",
    "section": "",
    "text": "If the generated probability distributions vary considerably, the selection of tokens might not be always among the most probable ones.\nGeneration of unique and varied sequences.\n\nTop-pGenerated text: I have a dream. I'm going to",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/26_sampling-and-structured-outputs.html#structured-outputs-1",
    "href": "slides/26_sampling-and-structured-outputs.html#structured-outputs-1",
    "title": "26. Sampling and Structured Outputs",
    "section": "Structured Outputs",
    "text": "Structured Outputs\nIf the LMM is a component of a larger system or pipeline, we need a way to pass the output as an input of another component.\nWe need to work with schemas such as:\n\nJSON\nPydantic: data validation library for Ptyhion.\n\nIt ensures data from LLM is accurate and valid\n\nOutlines: make the LLMs speak the language of every application.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "26. Sampling and Structured Outputs"
    ]
  },
  {
    "objectID": "slides/49_normalizing-flows.html#slide",
    "href": "slides/49_normalizing-flows.html#slide",
    "title": "49. Normalizing Flows",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "49. Normalizing Flows"
    ]
  },
  {
    "objectID": "slides/49_normalizing-flows.html#slide-1",
    "href": "slides/49_normalizing-flows.html#slide-1",
    "title": "49. Normalizing Flows",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "49. Normalizing Flows"
    ]
  },
  {
    "objectID": "slides/49_normalizing-flows.html#slide-2",
    "href": "slides/49_normalizing-flows.html#slide-2",
    "title": "49. Normalizing Flows",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "49. Normalizing Flows"
    ]
  },
  {
    "objectID": "slides/49_normalizing-flows.html#slide-3",
    "href": "slides/49_normalizing-flows.html#slide-3",
    "title": "49. Normalizing Flows",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "49. Normalizing Flows"
    ]
  },
  {
    "objectID": "slides/30_tool-use-and-agents.html#slide",
    "href": "slides/30_tool-use-and-agents.html#slide",
    "title": "30. Tool Use and ‘Agents’",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "30. Tool Use and 'Agents'"
    ]
  },
  {
    "objectID": "slides/30_tool-use-and-agents.html#slide-1",
    "href": "slides/30_tool-use-and-agents.html#slide-1",
    "title": "30. Tool Use and ‘Agents’",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "30. Tool Use and 'Agents'"
    ]
  },
  {
    "objectID": "slides/30_tool-use-and-agents.html#slide-2",
    "href": "slides/30_tool-use-and-agents.html#slide-2",
    "title": "30. Tool Use and ‘Agents’",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "30. Tool Use and 'Agents'"
    ]
  },
  {
    "objectID": "slides/30_tool-use-and-agents.html#slide-3",
    "href": "slides/30_tool-use-and-agents.html#slide-3",
    "title": "30. Tool Use and ‘Agents’",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "30. Tool Use and 'Agents'"
    ]
  },
  {
    "objectID": "slides/25_benchmarking.html#examples-of-evaluation-benchmarks",
    "href": "slides/25_benchmarking.html#examples-of-evaluation-benchmarks",
    "title": "25. Benchmarking",
    "section": "Examples of evaluation benchmarks",
    "text": "Examples of evaluation benchmarks\nHugginFace OpenLLM Leaderboard\n\nROUGE (Recall-Oriented Understudy for Gisting Evaluation) and BLEU (Bilingual Evaluation Understudy): Traditional metrics to evaluate the quality of text generated by LLMs.\nGLUE/SuperGLUE (General Language Understanding Evaluation). Evaluation on tasks that require deeper understanding of the language: text similarity, natural language inference, and sentiment analysis.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "25. Benchmarking"
    ]
  },
  {
    "objectID": "slides/25_benchmarking.html#section",
    "href": "slides/25_benchmarking.html#section",
    "title": "25. Benchmarking",
    "section": "",
    "text": "MMLU (Massive Multi-task Language Understanding). Favorite eval of DeepMind and Google.\n\nIt tests the model’s ability to generalize across different fields: maths, science, history, etc.\nHow well the model que transfer knowledge cross different domains.\n\nGSM8K (Grade School Math 8K). To eval reasoning combined with chain-of-thought.\n\nDataset of 8,500 high-quality, linguistically diverse grade school math word problems.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "25. Benchmarking"
    ]
  },
  {
    "objectID": "slides/25_benchmarking.html#section-1",
    "href": "slides/25_benchmarking.html#section-1",
    "title": "25. Benchmarking",
    "section": "",
    "text": "MATH. Used in most LLM papers.\n\n12,500 problems sourced from high school math competition.\n\nHumanEval. For coding. Developed by OpenAI.\n\nIt focuses on the models’ ability to comprehend language, reason, and solve problems related to algorithms and simple mathematics.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "25. Benchmarking"
    ]
  },
  {
    "objectID": "slides/25_benchmarking.html#what-makes-a-good-eval",
    "href": "slides/25_benchmarking.html#what-makes-a-good-eval",
    "title": "25. Benchmarking",
    "section": "What makes a good eval?",
    "text": "What makes a good eval?\n\nThey should measure things central to intelligence, be on a meaningful task.\nIt should be easy to understand.\nIt shouldn’t fluctuate based on the prompt.\nIt shouldn’t make mistakes.\nIt shouldn’t take too much work to run.\nThe grading should be correct.\nIt should provide examples.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "25. Benchmarking"
    ]
  },
  {
    "objectID": "slides/50_diffusion-models.html#rooms",
    "href": "slides/50_diffusion-models.html#rooms",
    "title": "50. Diffusion Models",
    "section": "rooms",
    "text": "rooms\n\nmodifications to pictures\nimage source: Radford, et al, 2016",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "50. Diffusion Models"
    ]
  },
  {
    "objectID": "slides/50_diffusion-models.html#filters",
    "href": "slides/50_diffusion-models.html#filters",
    "title": "50. Diffusion Models",
    "section": "filters",
    "text": "filters\n\ntrained filters\nimage source: Radford, et al, 2016",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "50. Diffusion Models"
    ]
  },
  {
    "objectID": "slides/50_diffusion-models.html#image-space",
    "href": "slides/50_diffusion-models.html#image-space",
    "title": "50. Diffusion Models",
    "section": "Image Space",
    "text": "Image Space\n\nvector space of images\nimage source: Deep Learning Illustrated",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "50. Diffusion Models"
    ]
  },
  {
    "objectID": "slides/50_diffusion-models.html#ex1",
    "href": "slides/50_diffusion-models.html#ex1",
    "title": "50. Diffusion Models",
    "section": "ex1",
    "text": "ex1\n\nimage space\nimage source: Radford, et al, 2016",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "50. Diffusion Models"
    ]
  },
  {
    "objectID": "slides/50_diffusion-models.html#ex2",
    "href": "slides/50_diffusion-models.html#ex2",
    "title": "50. Diffusion Models",
    "section": "ex2",
    "text": "ex2\n\nimage space\nimage source: Radford, et al, 2016",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "50. Diffusion Models"
    ]
  },
  {
    "objectID": "slides/50_diffusion-models.html#diffusion-models-1",
    "href": "slides/50_diffusion-models.html#diffusion-models-1",
    "title": "50. Diffusion Models",
    "section": "Diffusion Models",
    "text": "Diffusion Models\n\nA (denoising) diffusion model isn’t that complex if you compare it to other generative models such as Normalizing Flows, GANs or VAEs: they all convert noise from some simple distribution to a data sample. This is also the case here where a neural network learns to gradually denoise data starting from pure noise.\n\n—HuggingFace\n\nU-net architecture\nimage source: HuggingFace",
    "crumbs": [
      "Section VIII: Generative Modeling Beyond Sequences",
      "50. Diffusion Models"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#what-is-pretraining",
    "href": "slides/15_pretraining-recipes.html#what-is-pretraining",
    "title": "15. Pretraining Recipes",
    "section": "What is Pretraining?",
    "text": "What is Pretraining?\n\nTraining an LLM from scratch on a large corpus (e.g., Common Crawl)\nObjective: Predict next token in text\nOutput: A “base” model for later finetuning\nConnects to decoder-only Transformers (Section II)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#pretraining-the-big-picture",
    "href": "slides/15_pretraining-recipes.html#pretraining-the-big-picture",
    "title": "15. Pretraining Recipes",
    "section": "Pretraining: The Big Picture",
    "text": "Pretraining: The Big Picture\n\nProcess of training a model on vast amounts of text data\nSelf-supervised learning: predict next token or masked tokens\nGoal: Develop general language understanding capabilities\nResource-intensive: requires significant compute, data, engineering\nMany design choices affect training efficiency and model quality",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#building-on-previous-chapters",
    "href": "slides/15_pretraining-recipes.html#building-on-previous-chapters",
    "title": "15. Pretraining Recipes",
    "section": "Building on Previous Chapters",
    "text": "Building on Previous Chapters\n\nTransformer Architecture: Foundation of modern LLMs\nTokenization: Converting text to model-readable tokens\nPositional Encoding: Representing sequence information\nHere we examine: How to effectively train these models?",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#core-architectural-choices",
    "href": "slides/15_pretraining-recipes.html#core-architectural-choices",
    "title": "15. Pretraining Recipes",
    "section": "Core Architectural Choices",
    "text": "Core Architectural Choices\nKey decisions when pretraining LLMs:\n\nAttention mechanisms\nActivation functions\nNormalization approaches\nModel sizing & dimensionality",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#attention-mechanism-variants",
    "href": "slides/15_pretraining-recipes.html#attention-mechanism-variants",
    "title": "15. Pretraining Recipes",
    "section": "Attention Mechanism Variants",
    "text": "Attention Mechanism Variants\nThree main approaches:\n\nMulti-Head Attention (MHA): - Original Transformer design - Multiple attention heads, each with full query/key/value projections - Most expressive but computationally expensive\nMulti-Query Attention (MQA): - Shared key and value projections across heads - Queries remain separate - Reduces memory bandwidth requirements\nGrouped-Query Attention (GQA): - Middle ground between MHA and MQA - Keys and values shared among groups of heads - Better balance of efficiency and expressiveness",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#key-decisions-in-pretraining",
    "href": "slides/15_pretraining-recipes.html#key-decisions-in-pretraining",
    "title": "15. Pretraining Recipes",
    "section": "Key Decisions in Pretraining",
    "text": "Key Decisions in Pretraining\n\nNo one-size-fits-all “recipe”\nChoices impact performance, cost, speed\nCore areas:\n\nModel architecture (e.g., attention)\nTraining setup (e.g., optimization)\nData handling",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#attention-variants-trade-offs",
    "href": "slides/15_pretraining-recipes.html#attention-variants-trade-offs",
    "title": "15. Pretraining Recipes",
    "section": "Attention Variants: Trade-offs",
    "text": "Attention Variants: Trade-offs\n\n\n\n\n\n\n\n\n\n\n\nVariant\nParameters\nMemory\nQuality\nUsed In\n\n\n\n\nMHA\nHighest\nHighest\nHighest\nEarly models, high-quality research\n\n\nMQA\nLowest\nLowest\nLowest\nDeployment-optimized models\n\n\nGQA\nMedium\nMedium\nMedium\nModern balanced models (Claude, PaLM)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#attention-variants-mqa-vs-gqa-vs-mha",
    "href": "slides/15_pretraining-recipes.html#attention-variants-mqa-vs-gqa-vs-mha",
    "title": "15. Pretraining Recipes",
    "section": "Attention Variants: MQA vs GQA vs MHA",
    "text": "Attention Variants: MQA vs GQA vs MHA\nAttention Variants Comparison",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#activation-functions",
    "href": "slides/15_pretraining-recipes.html#activation-functions",
    "title": "15. Pretraining Recipes",
    "section": "Activation Functions",
    "text": "Activation Functions\nEvolution of activation functions in LLMs:\n\n- ReLU: Simple, efficient, but limited expressiveness\n- GeLU: Smoother variant of ReLU, used in many models\n- SwiGLU: Swish + GLU combination, better performance - Used in PaLM, LLaMA, and other recent models - Computationally more expensive but better results\n\n\nImpacts how neurons “fire” in Transformers",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#plot-of-relu-vs.-gelu",
    "href": "slides/15_pretraining-recipes.html#plot-of-relu-vs.-gelu",
    "title": "15. Pretraining Recipes",
    "section": "Plot of ReLU vs. GeLU",
    "text": "Plot of ReLU vs. GeLU",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#swiglu-the-modern-standard",
    "href": "slides/15_pretraining-recipes.html#swiglu-the-modern-standard",
    "title": "15. Pretraining Recipes",
    "section": "SwiGLU: The Modern Standard",
    "text": "SwiGLU: The Modern Standard\nSwiGLU computation:\n\\(\\text{SwiGLU}(x) = \\text{Swish}(xW) \\otimes (xV)\\)\nWhere:\n\n\\[\\text{Swish}(x) = x \\cdot \\text{sigmoid}(\\beta x)\\]\n\\[\\otimes \\text{ denotes element-wise multiplication}\\]\n\nBenefits:\n\nBetter gradient flow\n\nImproved representational capacity\n\nModest compute overhead for significant quality gains",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#normalization-techniques",
    "href": "slides/15_pretraining-recipes.html#normalization-techniques",
    "title": "15. Pretraining Recipes",
    "section": "Normalization Techniques",
    "text": "Normalization Techniques\n\nLayer Normalization: Standard in Transformers\n\nNormalizes across feature dimension\nStabilizes training\n\nRMSNorm: Simplified version of LayerNorm\n\nRemoves mean-centering step\nSlightly faster computation\nUsed in LLaMA and other recent models",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#optimization-strategies",
    "href": "slides/15_pretraining-recipes.html#optimization-strategies",
    "title": "15. Pretraining Recipes",
    "section": "Optimization Strategies",
    "text": "Optimization Strategies\nKey components:\n\nOptimizer choice\nLearning rate scheduling\nWeight decay\nGradient clipping",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#optimizers-for-llms",
    "href": "slides/15_pretraining-recipes.html#optimizers-for-llms",
    "title": "15. Pretraining Recipes",
    "section": "Optimizers for LLMs",
    "text": "Optimizers for LLMs\n\nAdamW: Standard choice for most LLMs\n\nAdaptive learning rates with proper weight decay\nRobust to hyperparameter choices\n\nAdafactor: Memory-efficient alternative\n\nFactorizes second moment matrices\nUseful for memory-constrained settings\n\nLion: Recent lightweight optimizer\n\nMomentum-based with sign updates\nLess memory usage, competitive performance",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#learning-rate-scheduling",
    "href": "slides/15_pretraining-recipes.html#learning-rate-scheduling",
    "title": "15. Pretraining Recipes",
    "section": "Learning Rate Scheduling",
    "text": "Learning Rate Scheduling\nTypical LLM learning rate schedule:\n\nWarmup phase: Gradually increase from small value\n\nPrevents early instability\nUsually 1-3% of total training steps\n\nDecay phase: Gradual reduction of learning rate\n\nCosine decay: Smooth reduction to minimum value\nLinear decay: Simpler alternative",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#learning-rate-schedule",
    "href": "slides/15_pretraining-recipes.html#learning-rate-schedule",
    "title": "15. Pretraining Recipes",
    "section": "Learning Rate Schedule",
    "text": "Learning Rate Schedule",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#effective-batch-sizing",
    "href": "slides/15_pretraining-recipes.html#effective-batch-sizing",
    "title": "15. Pretraining Recipes",
    "section": "Effective Batch Sizing",
    "text": "Effective Batch Sizing\n\nGlobal batch size: Total number of sequences processed before update\nMicro-batch size: Sequences processed on each device\nGradient accumulation: Accumulate gradients over multiple micro-batches\n\nKey considerations: - Larger batches → better gradient estimates but diminishing returns - Memory constraints often limit micro-batch size - Typical global batch sizes: 1-8 million tokens",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#dropout-strategies",
    "href": "slides/15_pretraining-recipes.html#dropout-strategies",
    "title": "15. Pretraining Recipes",
    "section": "Dropout Strategies",
    "text": "Dropout Strategies\n\nEarly LLMs: Significant dropout (0.1-0.2)\nModern trend: Minimal or no dropout\n\nChinchilla scaling laws: data &gt; regularization\nCurrent practice: Use dropout only for small models or limited data\n\nWhen used, applied to:\n\nAttention outputs\nFeed-forward outputs\nEmbedding layers",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#training-duration-and-data-reuse",
    "href": "slides/15_pretraining-recipes.html#training-duration-and-data-reuse",
    "title": "15. Pretraining Recipes",
    "section": "Training Duration and Data Reuse",
    "text": "Training Duration and Data Reuse\n\nEpoch: One pass through the entire dataset\nModern LLMs rarely see full epochs\nTokens seen during training:\n\nGPT-3: 300B tokens\nPaLM: 780B tokens\nLLaMA 2: 2T tokens\nClaude/GPT-4: 10T+ tokens (estimated)\n\nData mixing: Different sources with different sampling weights\nData repetition: Strategic repeating of high-quality data",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#scaling-laws-and-compute-optimal-training",
    "href": "slides/15_pretraining-recipes.html#scaling-laws-and-compute-optimal-training",
    "title": "15. Pretraining Recipes",
    "section": "Scaling Laws and Compute-Optimal Training",
    "text": "Scaling Laws and Compute-Optimal Training\n\nChinchilla scaling laws (DeepMind, 2022):\n\nModel size and training data should scale together\nOptimal tokens ≈ 20x parameter count\nE.g., 70B model → 1.4T tokens for optimal training\n\nCompute-optimal training:\n\nBalance model size, data, and training time given fixed compute budget",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#hyperparameter-selection",
    "href": "slides/15_pretraining-recipes.html#hyperparameter-selection",
    "title": "15. Pretraining Recipes",
    "section": "Hyperparameter Selection",
    "text": "Hyperparameter Selection\n\nModern approach: Much less tuning than traditional ML\nFocus on proven defaults from literature\nKey hyperparameters to tune:\n\nLearning rate and schedule\nWeight decay\nModel width/depth ratio\nGlobal batch size",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#engineering-considerations",
    "href": "slides/15_pretraining-recipes.html#engineering-considerations",
    "title": "15. Pretraining Recipes",
    "section": "Engineering Considerations",
    "text": "Engineering Considerations\n\nMixed precision training: fp16/bf16 + fp32 optimizer states\nGradient checkpointing: Trade computation for memory\nModel parallelism: Distribute model across devices\nData parallelism: Process different batches on different devices\nZero Redundancy Optimizer (ZeRO): Partition optimizer states\nFlashAttention: Efficient attention implementation",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#industry-best-practices",
    "href": "slides/15_pretraining-recipes.html#industry-best-practices",
    "title": "15. Pretraining Recipes",
    "section": "Industry Best Practices",
    "text": "Industry Best Practices\nRecent trends from leading labs:\n\nGQA + SwiGLU + RMSNorm architecture\nAdamW optimizer with cosine decay\n2-4M token batch sizes\nMinimal dropout\nCompute-optimal training allocation\nHeavy use of data curation and filtering",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#resources",
    "href": "slides/15_pretraining-recipes.html#resources",
    "title": "15. Pretraining Recipes",
    "section": "Resources",
    "text": "Resources\n\nA Recipe for Training Neural Networks by Andrej Karpathy\nThe Novice’s LLM Training Guide by Alpin Dale\nNavigating the Attention Landscape by Shobhit Agarwal\nChinchilla scaling laws paper",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/15_pretraining-recipes.html#key-takeaways",
    "href": "slides/15_pretraining-recipes.html#key-takeaways",
    "title": "15. Pretraining Recipes",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nMany architectural and training choices affect LLM performance\nModern defaults have emerged through industry experimentation\nBalancing compute efficiency and model quality is crucial\nBoth architecture and optimization strategy matter significantly\nNo single “best recipe” - depends on resources and goals",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "15. Pretraining Recipes"
    ]
  },
  {
    "objectID": "slides/03_time-series-analysis.html#stepping-forward",
    "href": "slides/03_time-series-analysis.html#stepping-forward",
    "title": "3. Time-Series Analysis",
    "section": "Stepping Forward",
    "text": "Stepping Forward\n\ntime series knowledge",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "3. Time-Series Analysis"
    ]
  },
  {
    "objectID": "slides/03_time-series-analysis.html#mermaid-code",
    "href": "slides/03_time-series-analysis.html#mermaid-code",
    "title": "3. Time-Series Analysis",
    "section": "Mermaid code",
    "text": "Mermaid code",
    "crumbs": [
      "Section I: Foundations of Sequential Prediction",
      "3. Time-Series Analysis"
    ]
  },
  {
    "objectID": "slides/52_vq-vae.html#variational-auto-encoders-1",
    "href": "slides/52_vq-vae.html#variational-auto-encoders-1",
    "title": "52. VQ-VAE",
    "section": "Variational Auto-Encoders",
    "text": "Variational Auto-Encoders\nIn AI architecture, variational autoencoders simulate the latent space (between the encoder and decoder)—usually with a mixture of Gaussian functions—to maximize the ELBO (evidence lower bound)\n\nVAE Gaussians\nimage source",
    "crumbs": [
      "Section IX: Multimodal Models",
      "52. VQ-VAE"
    ]
  },
  {
    "objectID": "slides/52_vq-vae.html#without",
    "href": "slides/52_vq-vae.html#without",
    "title": "52. VQ-VAE",
    "section": "without",
    "text": "without\n\nwithout VAE\nimage source: Jeff Orchard",
    "crumbs": [
      "Section IX: Multimodal Models",
      "52. VQ-VAE"
    ]
  },
  {
    "objectID": "slides/52_vq-vae.html#with",
    "href": "slides/52_vq-vae.html#with",
    "title": "52. VQ-VAE",
    "section": "with",
    "text": "with\n\nwith VAE\nimage source: Jeff Orchard",
    "crumbs": [
      "Section IX: Multimodal Models",
      "52. VQ-VAE"
    ]
  },
  {
    "objectID": "slides/52_vq-vae.html#vq-vae-1",
    "href": "slides/52_vq-vae.html#vq-vae-1",
    "title": "52. VQ-VAE",
    "section": "VQ-VAE",
    "text": "VQ-VAE\nVector quantized variational autoencoders (VQ-VAE) utilize an discrete embedding space\n\nfor example: 32x32 embedding space of vectors\n\n\nVQ-VAE\nimage source",
    "crumbs": [
      "Section IX: Multimodal Models",
      "52. VQ-VAE"
    ]
  },
  {
    "objectID": "slides/36_speculative-decoding.html#slide",
    "href": "slides/36_speculative-decoding.html#slide",
    "title": "36. Speculative Decoding",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "36. Speculative Decoding"
    ]
  },
  {
    "objectID": "slides/36_speculative-decoding.html#slide-1",
    "href": "slides/36_speculative-decoding.html#slide-1",
    "title": "36. Speculative Decoding",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "36. Speculative Decoding"
    ]
  },
  {
    "objectID": "slides/36_speculative-decoding.html#slide-2",
    "href": "slides/36_speculative-decoding.html#slide-2",
    "title": "36. Speculative Decoding",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "36. Speculative Decoding"
    ]
  },
  {
    "objectID": "slides/36_speculative-decoding.html#slide-3",
    "href": "slides/36_speculative-decoding.html#slide-3",
    "title": "36. Speculative Decoding",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "36. Speculative Decoding"
    ]
  },
  {
    "objectID": "slides/37_flashattention.html#slide",
    "href": "slides/37_flashattention.html#slide",
    "title": "37. FlashAttention",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "37. FlashAttention"
    ]
  },
  {
    "objectID": "slides/37_flashattention.html#slide-1",
    "href": "slides/37_flashattention.html#slide-1",
    "title": "37. FlashAttention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "37. FlashAttention"
    ]
  },
  {
    "objectID": "slides/37_flashattention.html#slide-2",
    "href": "slides/37_flashattention.html#slide-2",
    "title": "37. FlashAttention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "37. FlashAttention"
    ]
  },
  {
    "objectID": "slides/37_flashattention.html#slide-3",
    "href": "slides/37_flashattention.html#slide-3",
    "title": "37. FlashAttention",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section VI: Performance Optimizations for Efficient Inference",
      "37. FlashAttention"
    ]
  },
  {
    "objectID": "slides/51_tokenization-beyond-text.html#text",
    "href": "slides/51_tokenization-beyond-text.html#text",
    "title": "51. Tokenization Beyond Text",
    "section": "Text",
    "text": "Text\n\ntokenization of text\nimage source: Murilo Gustineli",
    "crumbs": [
      "Section IX: Multimodal Models",
      "51. Tokenization Beyond Text"
    ]
  },
  {
    "objectID": "slides/51_tokenization-beyond-text.html#vectorization",
    "href": "slides/51_tokenization-beyond-text.html#vectorization",
    "title": "51. Tokenization Beyond Text",
    "section": "Vectorization",
    "text": "Vectorization\n\ntokenization of images\nimages are partitioned into patches\neach patch is flattened into a vector\nimage source: Shusen Wang",
    "crumbs": [
      "Section IX: Multimodal Models",
      "51. Tokenization Beyond Text"
    ]
  },
  {
    "objectID": "slides/51_tokenization-beyond-text.html#positional-encoding",
    "href": "slides/51_tokenization-beyond-text.html#positional-encoding",
    "title": "51. Tokenization Beyond Text",
    "section": "Positional Encoding",
    "text": "Positional Encoding\n\npositional encoding of patches\nimage source: Shusen Wang",
    "crumbs": [
      "Section IX: Multimodal Models",
      "51. Tokenization Beyond Text"
    ]
  },
  {
    "objectID": "slides/51_tokenization-beyond-text.html#abstraction",
    "href": "slides/51_tokenization-beyond-text.html#abstraction",
    "title": "51. Tokenization Beyond Text",
    "section": "Abstraction",
    "text": "Abstraction\n\naudio abstraction\nimage source: Valerio Velardo",
    "crumbs": [
      "Section IX: Multimodal Models",
      "51. Tokenization Beyond Text"
    ]
  },
  {
    "objectID": "slides/51_tokenization-beyond-text.html#music",
    "href": "slides/51_tokenization-beyond-text.html#music",
    "title": "51. Tokenization Beyond Text",
    "section": "Music",
    "text": "Music\n\nbeat\ntimbre\npitch\nharmony\n…\nsource: Valerio Velardo",
    "crumbs": [
      "Section IX: Multimodal Models",
      "51. Tokenization Beyond Text"
    ]
  },
  {
    "objectID": "slides/51_tokenization-beyond-text.html#fourier",
    "href": "slides/51_tokenization-beyond-text.html#fourier",
    "title": "51. Tokenization Beyond Text",
    "section": "Fourier",
    "text": "Fourier\n\nsignal domain\nimage source: Valerio Velardo",
    "crumbs": [
      "Section IX: Multimodal Models",
      "51. Tokenization Beyond Text"
    ]
  },
  {
    "objectID": "slides/51_tokenization-beyond-text.html#trends",
    "href": "slides/51_tokenization-beyond-text.html#trends",
    "title": "51. Tokenization Beyond Text",
    "section": "Trends",
    "text": "Trends\n\ndigital signal processing \\(\\rightarrow\\) rule-based systems\ntraditional ML \\(\\rightarrow\\) feature engineering\ndeep learning \\(\\rightarrow\\) automatic feature engineering\nsource: Valerio Velardo",
    "crumbs": [
      "Section IX: Multimodal Models",
      "51. Tokenization Beyond Text"
    ]
  },
  {
    "objectID": "slides/10_embeddings-and-topic-modeling.html#slide",
    "href": "slides/10_embeddings-and-topic-modeling.html#slide",
    "title": "10. Embeddings and Topic Modeling",
    "section": "SLIDE",
    "text": "SLIDE\n\nDENOTE MAJOR SECTIONS WITH # TITLE (eg # Installation)\nADD INDIVIDUAL SLIDES WITH ## (eg ## rustup on Linux/macOS)\nKEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF.",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "10. Embeddings and Topic Modeling"
    ]
  },
  {
    "objectID": "slides/10_embeddings-and-topic-modeling.html#slide-1",
    "href": "slides/10_embeddings-and-topic-modeling.html#slide-1",
    "title": "10. Embeddings and Topic Modeling",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "10. Embeddings and Topic Modeling"
    ]
  },
  {
    "objectID": "slides/10_embeddings-and-topic-modeling.html#slide-2",
    "href": "slides/10_embeddings-and-topic-modeling.html#slide-2",
    "title": "10. Embeddings and Topic Modeling",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "10. Embeddings and Topic Modeling"
    ]
  },
  {
    "objectID": "slides/10_embeddings-and-topic-modeling.html#slide-3",
    "href": "slides/10_embeddings-and-topic-modeling.html#slide-3",
    "title": "10. Embeddings and Topic Modeling",
    "section": "SLIDE",
    "text": "SLIDE",
    "crumbs": [
      "Section II: Neural Sequential Prediction",
      "10. Embeddings and Topic Modeling"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#prompt-engineering",
    "href": "slides/27_prompting-techniques.html#prompt-engineering",
    "title": "27. Prompting Techniques",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nAlso known as In-Context Prompting\nHow to communicate with LLM to steer its behavior for desired outcomes without updating the model weights.\nIt is an empirical task (science?) and varies among models.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#techniques",
    "href": "slides/27_prompting-techniques.html#techniques",
    "title": "27. Prompting Techniques",
    "section": "Techniques",
    "text": "Techniques\n\nZero-shot: Feed the task text to the model and ask for results.\nFew-shot: Input/output of high quality examples on the target task.\n\nMore token consumption.\nChoice of prompt format, training examples, and order leads to different performance.\nThe selection of examples should be diverse and relevant.\nBe careful of majority label bias and recency bias",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#section",
    "href": "slides/27_prompting-techniques.html#section",
    "title": "27. Prompting Techniques",
    "section": "",
    "text": "Instruction prompting: Finetune technique on a pretrained model.\n\nInstructed LM Training with tuples of (task instruction, input, ground truth output)\nRLHF (Reinforcement Learning from Human Feedback) is a common method.\nIt improves the model to be more aligned with human intention.\n\n\n\nInstruction prompting",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#section-1",
    "href": "slides/27_prompting-techniques.html#section-1",
    "title": "27. Prompting Techniques",
    "section": "",
    "text": "Self-Consistency Sampling: Sample multiple outputs with temperature &gt; 0 and select the best.\n\nThe criteria for selecting the best candidate can vary from task to task. General solution: majority vote.\n\nChain-of-Thought (CoT): Generates a sequence describing reasoning logics step by step.\n\nSteps also known as reasoning chains or rationales.\nFor complicated reasoning tasks.\n\nFew-shot CoT: give examples\nZero shot: Use statements like Let's think step by step",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#other-techniques",
    "href": "slides/27_prompting-techniques.html#other-techniques",
    "title": "27. Prompting Techniques",
    "section": "Other techniques",
    "text": "Other techniques\n\n\n\nSelf-Ask: Prompt the model to ask following-up to build the thought process iteratively.\nIRCoT (Interleaving Retrieval CoT) and ReAct (Reason + Act) combine iterative CoT prompting with queries to Wikipedia APIs to add to the context.\n\n\n\n\n\nSelf Ask",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#automatic-prompt-design",
    "href": "slides/27_prompting-techniques.html#automatic-prompt-design",
    "title": "27. Prompting Techniques",
    "section": "Automatic Prompt Design",
    "text": "Automatic Prompt Design\nInput: prompt (sequence of prefix tokens).\nOptimization task: probability of getting a desired output given input.\nHow? Prefix tokens are optimized on the embedding space via gradient descent\n\nMultiple methods: AutoPrompt (Shin et al., 2020), Prefix-Tuning (Li & Liang (2021), P-tuning (Liu et al. 2021), Prompt-Tuning (Lester et al. 2021).\nAPE (Automatic Prompt Engineer; Zhou et al. 2022): It uses a score function to select the best candidate over a pool of model-generated instruction candidates.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#other-examples",
    "href": "slides/27_prompting-techniques.html#other-examples",
    "title": "27. Prompting Techniques",
    "section": "Other examples",
    "text": "Other examples\n\nPAL (Program-aided language models; Gao et al. 2022) and PoT (Program of Thoughts prompting; Chen et al. 2022): ask LLM to generate programming language statements.\n\n\nPoT",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/27_prompting-techniques.html#section-2",
    "href": "slides/27_prompting-techniques.html#section-2",
    "title": "27. Prompting Techniques",
    "section": "",
    "text": "TALM (Tool Augmented Language Models; Parisi et al. 2022): model augmented with text-to-text API calls. It builds API requests and calls them to append the result.",
    "crumbs": [
      "Section V: LLM Evaluations and Applications",
      "27. Prompting Techniques"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#tokenization",
    "href": "slides/13_tokenization.html#tokenization",
    "title": "13. Tokenization",
    "section": "Tokenization",
    "text": "Tokenization\n“Tokenization is at the heart of much weirdness of LLMs” - Karpathy\n\nWhy can’t LLM spell words? Tokenization.\nWhy can’t LLM do super simple string processing tasks? Tokenization.\nWhy is LLM worse at non-English languages (e.g. Japanese)? Tokenization.\nWhy is LLM bad at simple arithmetic? Tokenization.\nWhy did my LLM abruptly halt when it sees the string “&lt;/endoftext|&gt;”? Tokenization.\nWhy is LLM not actually end-to-end language modeling? Tokenization.\nWhat is the real root of suffering? Tokenization.",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#quick-recap-what-came-before-12",
    "href": "slides/13_tokenization.html#quick-recap-what-came-before-12",
    "title": "13. Tokenization",
    "section": "Quick Recap: What Came Before (1/2)",
    "text": "Quick Recap: What Came Before (1/2)\n\nIntroduction:\n\nThe AI Landscape\nThe Content Landscape\nPreliminaries : Math (Calculus, Linear algebra), Programming (Python basics)\n\nSection I: Foundations of Sequential Prediction\n\nStatistical Prediction & Supervised Learning\nTime-Series Analysis\nOnline Learning and Regret Minimization\nReinforcement Learning\nMarkov Models",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#quick-recap-what-came-before-22",
    "href": "slides/13_tokenization.html#quick-recap-what-came-before-22",
    "title": "13. Tokenization",
    "section": "Quick Recap: What Came Before (2/2)",
    "text": "Quick Recap: What Came Before (2/2)\n\nSection II: Neural Sequential Prediction\n\nStatistical Prediction with Neural Networks\nRecurrent Neural Networks (RNNs)\nLSTMs and GRUs (Long Short-Term Memory and Gated Recurrent Unit) networks\nEmbeddings and Topic Modeling\nEncoders and Decoders\nDecoder-Only Transformers",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#why-this-matters",
    "href": "slides/13_tokenization.html#why-this-matters",
    "title": "13. Tokenization",
    "section": "Why This Matters",
    "text": "Why This Matters\n\nBuilds from decoder-only Transformers to Modern LLM Foundations\nKey questions:\n\nHow do we process text efficiently?\nHow do we encode word order without recurrence?\n\nRapid AI progress (Where we were in 2022 → today)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#what-is-tokenization",
    "href": "slides/13_tokenization.html#what-is-tokenization",
    "title": "13. Tokenization",
    "section": "What is Tokenization?",
    "text": "What is Tokenization?\n\nConverting text into manageable units (tokens) for LLMs\nWhy it’s critical:\n\nLLMs process tokens, not raw characters or full words\nImpacts efficiency and generalization",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#tokenization-approaches",
    "href": "slides/13_tokenization.html#tokenization-approaches",
    "title": "13. Tokenization",
    "section": "Tokenization Approaches",
    "text": "Tokenization Approaches\n\nCharacter-level: Each char = token\n\nPros: Simple, handles all inputs\nCons: Inefficient (long sequences)\n\nWord-level: Each word = token\n\nPros: Intuitive, shorter sequences\nCons: Fixed vocab → unseen words/misspellings",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#subword-level-tokenization",
    "href": "slides/13_tokenization.html#subword-level-tokenization",
    "title": "13. Tokenization",
    "section": "Subword-Level Tokenization",
    "text": "Subword-Level Tokenization\n\nSolution: Split words into subword units.\nExample: “playing” → “play” + “##ing”\nAlgorithm: Byte-Pair Encoding (BPE)\nStarts with character-level tokens\nIteratively merges frequent pairs\nAnalogy: Huffman coding (but dynamic)\nResult: Compact, adaptive vocabulary\nSee Andrej Karpathy’s video for intuition",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#byte-pair-encoding-bpe",
    "href": "slides/13_tokenization.html#byte-pair-encoding-bpe",
    "title": "13. Tokenization",
    "section": "Byte-Pair Encoding (BPE)",
    "text": "Byte-Pair Encoding (BPE)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#bpe-example",
    "href": "slides/13_tokenization.html#bpe-example",
    "title": "13. Tokenization",
    "section": "BPE Example",
    "text": "BPE Example\n\nText: “low lower lowest”\nInitial: l o w, l o w e r, l o w e s t\nMerge lo → low\nMerge low + e → lowe\nFinal vocab: low, lowe, r, s, t\n\n\n\nBPE builds a vocabulary by finding and combining frequent patterns. Here, it learned that “low” is a common base in all three words, and “lowe” is a common base in “lower” and “lowest”. The leftover letters (r, s, t) are treated as separate tokens.\nThis is the input text we’re working with. It’s three words: “low”, “lower”, and “lowest”. BPE will analyze this text to find common patterns and create a vocabulary.\nAt the start, BPE treats every word as a sequence of individual characters, with spaces between them for clarity. So: “low” becomes l o w “lower” becomes l o w e r “lowest” becomes l o w e s t Think of these as the smallest units (individual characters) that BPE begins with. At this point, the vocabulary is just the individual letters: l, o, w, e, r, s, t.",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  },
  {
    "objectID": "slides/13_tokenization.html#why-subword-tokenization",
    "href": "slides/13_tokenization.html#why-subword-tokenization",
    "title": "13. Tokenization",
    "section": "Why Subword Tokenization?",
    "text": "Why Subword Tokenization?\n\nCovers unseen words (e.g., “lowering” → “lowe” + “r” + “##ing”)\nReduces sequence length vs. character-level\nUsed in most modern LLMs (e.g., GPT, BERT)",
    "crumbs": [
      "Section III: Foundations for Modern Language Modeling",
      "13. Tokenization"
    ]
  }
]